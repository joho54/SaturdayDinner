import os
import sys
import json
import numpy as np
import tensorflow as tf
import mediapipe as mp
import cv2
from tqdm import tqdm
from sklearn.model_selection import train_test_split
from tensorflow.keras.utils import to_categorical
import pickle

# MediaPipe ì„¤ì •
mp_holistic = mp.solutions.holistic
holistic = mp_holistic.Holistic(
    static_image_mode=False,
    model_complexity=1,
    smooth_landmarks=True,
    enable_segmentation=False,
    smooth_segmentation=True,
    min_detection_confidence=0.5,
    min_tracking_confidence=0.5,
)

# ì„¤ì •
TARGET_SEQ_LENGTH = 30
AUGMENTATIONS_PER_VIDEO = 3
NONE_CLASS = "None"

# ìºì‹œ ë””ë ‰í† ë¦¬ ì„¤ì •
CACHE_DIR = "cache"
os.makedirs(CACHE_DIR, exist_ok=True)

# ë¼ë²¨ë³„ ìºì‹œ íŒŒì¼ ê²½ë¡œ ìƒì„± í•¨ìˆ˜
def get_label_cache_path(label):
    """ë¼ë²¨ë³„ ìºì‹œ íŒŒì¼ ê²½ë¡œë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤."""
    safe_label = label.replace(" ", "_").replace("/", "_")
    return os.path.join(CACHE_DIR, f"{safe_label}_data.pkl")

def save_label_cache(label, data):
    """ë¼ë²¨ë³„ ë°ì´í„°ë¥¼ ìºì‹œì— ì €ì¥í•©ë‹ˆë‹¤."""
    cache_path = get_label_cache_path(label)
    with open(cache_path, 'wb') as f:
        pickle.dump(data, f)
    print(f"ğŸ’¾ {label} ë¼ë²¨ ë°ì´í„° ìºì‹œ ì €ì¥: {cache_path}")

def load_label_cache(label):
    """ë¼ë²¨ë³„ ë°ì´í„°ë¥¼ ìºì‹œì—ì„œ ë¡œë“œí•©ë‹ˆë‹¤."""
    cache_path = get_label_cache_path(label)
    if os.path.exists(cache_path):
        with open(cache_path, 'rb') as f:
            data = pickle.load(f)
        print(f"ğŸ“‚ {label} ë¼ë²¨ ë°ì´í„° ìºì‹œ ë¡œë“œ: {cache_path}")
        return data
    return None

def extract_landmarks(video_path):
    """ë¹„ë””ì˜¤ì—ì„œ ëœë“œë§ˆí¬ë¥¼ ì¶”ì¶œí•©ë‹ˆë‹¤."""
    cap = cv2.VideoCapture(video_path)
    landmarks_list = []
    
    while cap.isOpened():
        ret, frame = cap.read()
        if not ret:
            break
            
        # BGR to RGB
        image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
        image.flags.writeable = False
        
        # MediaPipe ì²˜ë¦¬
        results = holistic.process(image)
        
        # ëœë“œë§ˆí¬ ì €ì¥
        landmarks_list.append(results)
    
    cap.release()
    return landmarks_list

def improved_preprocess_landmarks(landmarks_list):
    """ëœë“œë§ˆí¬ë¥¼ ì „ì²˜ë¦¬í•©ë‹ˆë‹¤."""
    if not landmarks_list:
        return None
    
    # ì‹œí€€ìŠ¤ ê¸¸ì´ ì •ê·œí™”
    if len(landmarks_list) > TARGET_SEQ_LENGTH:
        # ë” ê¸´ ì‹œí€€ìŠ¤ëŠ” ê· ë“±í•˜ê²Œ ìƒ˜í”Œë§
        indices = np.linspace(0, len(landmarks_list) - 1, TARGET_SEQ_LENGTH, dtype=int)
        landmarks_list = [landmarks_list[i] for i in indices]
    elif len(landmarks_list) < TARGET_SEQ_LENGTH:
        # ë” ì§§ì€ ì‹œí€€ìŠ¤ëŠ” ë§ˆì§€ë§‰ í”„ë ˆì„ìœ¼ë¡œ íŒ¨ë”©
        last_frame = landmarks_list[-1]
        while len(landmarks_list) < TARGET_SEQ_LENGTH:
            landmarks_list.append(last_frame)
    
    # ëœë“œë§ˆí¬ë¥¼ ë°°ì—´ë¡œ ë³€í™˜
    sequence = []
    for landmarks in landmarks_list:
        frame_features = []
        
        # Pose landmarks (33ê°œ)
        if landmarks.pose_landmarks:
            for lm in landmarks.pose_landmarks.landmark:
                frame_features.extend([lm.x, lm.y, lm.z])
        else:
            frame_features.extend([0, 0, 0] * 33)
        
        # Left hand landmarks (21ê°œ)
        if landmarks.left_hand_landmarks:
            for lm in landmarks.left_hand_landmarks.landmark:
                frame_features.extend([lm.x, lm.y, lm.z])
        else:
            frame_features.extend([0, 0, 0] * 21)
        
        # Right hand landmarks (21ê°œ)
        if landmarks.right_hand_landmarks:
            for lm in landmarks.right_hand_landmarks.landmark:
                frame_features.extend([lm.x, lm.y, lm.z])
        else:
            frame_features.extend([0, 0, 0] * 21)
        
        sequence.append(frame_features)
    
    return np.array(sequence)

def augment_sequence_improved(sequence, noise_level=0.05, scale_range=0.2, rotation_range=0.1):
    """ì‹œí€€ìŠ¤ë¥¼ ì¦ê°•í•©ë‹ˆë‹¤."""
    augmented = sequence.copy()
    
    # ë…¸ì´ì¦ˆ ì¶”ê°€
    noise = np.random.normal(0, noise_level, augmented.shape)
    augmented += noise
    
    # ìŠ¤ì¼€ì¼ë§
    scale_factor = np.random.uniform(1 - scale_range, 1 + scale_range)
    augmented *= scale_factor
    
    # íšŒì „ (ê°„ë‹¨í•œ íšŒì „)
    angle = np.random.uniform(-rotation_range, rotation_range)
    cos_a, sin_a = np.cos(angle), np.sin(angle)
    rotation_matrix = np.array([[cos_a, -sin_a], [sin_a, cos_a]])
    
    # x, y ì¢Œí‘œì—ë§Œ íšŒì „ ì ìš©
    for i in range(augmented.shape[0]):
        for j in range(0, augmented.shape[1], 3):  # x, y, z ìˆœì„œ
            if j + 1 < augmented.shape[1]:
                xy = np.array([augmented[i, j], augmented[i, j + 1]])
                rotated_xy = rotation_matrix @ xy
                augmented[i, j] = rotated_xy[0]
                augmented[i, j + 1] = rotated_xy[1]
    
    return augmented

def extract_and_cache_label_data(file_mapping, label):
    """íŠ¹ì • ë¼ë²¨ì˜ ë°ì´í„°ë¥¼ ì¶”ì¶œí•˜ê³  ìºì‹œì— ì €ì¥í•©ë‹ˆë‹¤."""
    print(f"\nğŸ”„ {label} ë¼ë²¨ ë°ì´í„° ì¶”ì¶œ ì¤‘...")
    
    # ìºì‹œ í™•ì¸
    cached_data = load_label_cache(label)
    if cached_data:
        print(f"âœ… {label} ë¼ë²¨ ìºì‹œ ë°ì´í„° ì‚¬ìš©: {len(cached_data)}ê°œ ìƒ˜í”Œ")
        return cached_data
    
    # í•´ë‹¹ ë¼ë²¨ì˜ íŒŒì¼ë“¤ë§Œ í•„í„°ë§
    label_files = {filename: info for filename, info in file_mapping.items() 
                  if info['label'] == label}
    
    if not label_files:
        print(f"âš ï¸ {label} ë¼ë²¨ì— í•´ë‹¹í•˜ëŠ” íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.")
        return []
    
    label_data = []
    
    for filename, info in tqdm(label_files.items(), desc=f"{label} ë°ì´í„° ì¶”ì¶œ"):
        file_path = info['path']
        
        try:
            landmarks = extract_landmarks(file_path)
            if not landmarks:
                print(f"âš ï¸ ëœë“œë§ˆí¬ ì¶”ì¶œ ì‹¤íŒ¨: {file_path}")
                continue

            processed_sequence = improved_preprocess_landmarks(landmarks)

            if processed_sequence.shape != (TARGET_SEQ_LENGTH, 675):
                print(f"âš ï¸ ì‹œí€€ìŠ¤ í˜•íƒœ ì˜¤ë¥˜: {processed_sequence.shape}")
                continue

            # ì›ë³¸ ë°ì´í„° ì¶”ê°€
            label_data.append(processed_sequence)

            # ì¦ê°• ë°ì´í„° ì¶”ê°€
            for _ in range(AUGMENTATIONS_PER_VIDEO):
                try:
                    augmented = augment_sequence_improved(processed_sequence)
                    if augmented.shape == (TARGET_SEQ_LENGTH, 675):
                        label_data.append(augmented)
                except Exception as e:
                    print(f"âš ï¸ ì¦ê°• ì¤‘ ì˜¤ë¥˜: {e}")
                    continue
                    
        except Exception as e:
            print(f"âš ï¸ íŒŒì¼ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {filename}, ì˜¤ë¥˜: {e}")
            continue
    
    print(f"âœ… {label} ë¼ë²¨ ë°ì´í„° ì¶”ì¶œ ì™„ë£Œ: {len(label_data)}ê°œ ìƒ˜í”Œ")
    
    # ìºì‹œì— ì €ì¥
    save_label_cache(label, label_data)
    
    return label_data

def generate_none_class_data(file_mapping):
    """None í´ë˜ìŠ¤ ë°ì´í„°ë¥¼ ìƒì„±í•˜ê³  ìºì‹œì— ì €ì¥í•©ë‹ˆë‹¤."""
    print(f"\nâœ¨ '{NONE_CLASS}' í´ë˜ìŠ¤ ë°ì´í„° ìƒì„± ì¤‘...")
    
    # ê¸°ì¡´ ìºì‹œ í™•ì¸
    cached_none_data = load_label_cache(NONE_CLASS)
    if cached_none_data:
        print(f"âœ… {NONE_CLASS} í´ë˜ìŠ¤ ìºì‹œ ë°ì´í„° ì‚¬ìš©: {len(cached_none_data)}ê°œ ìƒ˜í”Œ")
        return cached_none_data
    
    none_samples = []
    source_videos = list(file_mapping.keys())

    for filename in tqdm(source_videos, desc="None í´ë˜ìŠ¤ ë°ì´í„° ìƒì„±"):
        file_path = file_mapping[filename]['path']
        
        try:
            landmarks = extract_landmarks(file_path)
            if landmarks and len(landmarks) > 10:
                # ì˜ìƒì˜ ì‹œì‘, 1/4, 1/2, 3/4, ë ì§€ì ì—ì„œ í”„ë ˆì„ ì¶”ì¶œ
                frame_indices = [
                    0,
                    len(landmarks) // 4,
                    len(landmarks) // 2,
                    3 * len(landmarks) // 4,
                    -1,
                ]

                for idx in frame_indices:
                    static_landmarks = [landmarks[idx]] * TARGET_SEQ_LENGTH
                    static_sequence = improved_preprocess_landmarks(static_landmarks)

                    if static_sequence.shape != (TARGET_SEQ_LENGTH, 675):
                        continue

                    # ì •ì  ì‹œí€€ìŠ¤ ì¶”ê°€
                    none_samples.append(static_sequence)

                    # ë¯¸ì„¸í•œ ì›€ì§ì„ ì¶”ê°€ (ë…¸ì´ì¦ˆ)
                    for _ in range(3):
                        augmented = augment_sequence_improved(
                            static_sequence, noise_level=0.01
                        )
                        if augmented.shape == (TARGET_SEQ_LENGTH, 675):
                            none_samples.append(augmented)

                # ëŠë¦° ì „í™˜ ë°ì´í„° ìƒì„±
                start_frame_lm = landmarks[0]
                middle_frame_lm = landmarks[len(landmarks) // 2]

                transition_landmarks = []
                for i in range(TARGET_SEQ_LENGTH):
                    alpha = i / (TARGET_SEQ_LENGTH - 1)
                    interp_frame = {}
                    for key in ["pose", "left_hand", "right_hand"]:
                        if start_frame_lm.get(key) and middle_frame_lm.get(key):
                            interp_lm = []
                            start_lms = start_frame_lm[key].landmark
                            mid_lms = middle_frame_lm[key].landmark
                            for j in range(len(start_lms)):
                                new_x = (
                                    start_lms[j].x * (1 - alpha) + mid_lms[j].x * alpha
                                )
                                new_y = (
                                    start_lms[j].y * (1 - alpha) + mid_lms[j].y * alpha
                                )
                                new_z = (
                                    start_lms[j].z * (1 - alpha) + mid_lms[j].z * alpha
                                )
                                interp_lm.append(
                                    type(
                                        "obj",
                                        (object,),
                                        {"x": new_x, "y": new_y, "z": new_z},
                                    )
                                )
                            interp_frame[key] = type(
                                "obj", (object,), {"landmark": interp_lm}
                            )
                        else:
                            interp_frame[key] = None
                    transition_landmarks.append(interp_frame)

                transition_sequence = improved_preprocess_landmarks(
                    transition_landmarks
                )
                if transition_sequence.shape == (TARGET_SEQ_LENGTH, 675):
                    none_samples.append(transition_sequence)
        except Exception as e:
            print(f"âš ï¸ None í´ë˜ìŠ¤ ë°ì´í„° ìƒì„± ì¤‘ ì˜¤ë¥˜: {filename}, ì˜¤ë¥˜: {e}")
            continue

    print(f"âœ… {NONE_CLASS} í´ë˜ìŠ¤ ë°ì´í„° ìƒì„± ì™„ë£Œ: {len(none_samples)}ê°œ ìƒ˜í”Œ")
    
    # ìºì‹œì— ì €ì¥
    save_label_cache(NONE_CLASS, none_samples)
    
    return none_samples

def get_action_index(label):
    """ë¼ë²¨ì˜ ì¸ë±ìŠ¤ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤."""
    return ACTIONS.index(label)

def create_simple_model(input_shape, num_classes):
    """ê°„ë‹¨í•œ ëª¨ë¸ì„ ìƒì„±í•©ë‹ˆë‹¤."""
    model = tf.keras.Sequential([
        tf.keras.layers.LSTM(128, return_sequences=True, input_shape=input_shape),
        tf.keras.layers.Dropout(0.3),
        tf.keras.layers.LSTM(64, return_sequences=False),
        tf.keras.layers.Dropout(0.3),
        tf.keras.layers.Dense(32, activation='relu'),
        tf.keras.layers.Dropout(0.3),
        tf.keras.layers.Dense(num_classes, activation='softmax')
    ])
    return model

def process_all_labels(file_mapping, actions):
    """ëª¨ë“  ë¼ë²¨ì˜ ë°ì´í„°ë¥¼ ì²˜ë¦¬í•˜ê³  ìºì‹œì— ì €ì¥í•©ë‹ˆë‹¤."""
    print("ğŸš€ ë¼ë²¨ë³„ ë°ì´í„° ì¶”ì¶œ ë° ìºì‹± ì‹œì‘...")
    
    all_data = {}
    
    # ê° ë¼ë²¨ë³„ë¡œ ë°ì´í„° ì¶”ì¶œ
    for label in actions:
        if label == NONE_CLASS:
            label_data = generate_none_class_data(file_mapping)
        else:
            label_data = extract_and_cache_label_data(file_mapping, label)
        
        all_data[label] = label_data
    
    return all_data

def combine_all_data(all_data, actions):
    """ëª¨ë“  ë¼ë²¨ì˜ ë°ì´í„°ë¥¼ ê²°í•©í•©ë‹ˆë‹¤."""
    print("\nğŸ”— ëª¨ë“  ë¼ë²¨ ë°ì´í„° ê²°í•© ì¤‘...")
    
    X = []
    y = []
    
    for label in actions:
        if label in all_data and all_data[label]:
            label_data = all_data[label]
            label_index = get_action_index(label)
            
            X.extend(label_data)
            y.extend([label_index] * len(label_data))
            
            print(f"âœ… {label}: {len(label_data)}ê°œ ìƒ˜í”Œ ì¶”ê°€")
    
    print(f"\nğŸ“Š ìµœì¢… ë°ì´í„° í†µê³„:")
    print(f"ì´ ìƒ˜í”Œ ìˆ˜: {len(X)}")
    
    # í´ë˜ìŠ¤ë³„ ìƒ˜í”Œ ìˆ˜ í™•ì¸
    unique, counts = np.unique(y, return_counts=True)
    for class_idx, count in zip(unique, counts):
        if 0 <= class_idx < len(actions):
            print(f"í´ë˜ìŠ¤ {class_idx} ({actions[class_idx]}): {count}ê°œ")
        else:
            print(f"í´ë˜ìŠ¤ {class_idx} (Unknown): {count}ê°œ")
    
    return np.array(X), np.array(y)

if __name__ == "__main__":
    # ì´ íŒŒì¼ì€ ë¼ë²¨ë³„ ìºì‹± ì‹œìŠ¤í…œì„ ì œê³µí•˜ëŠ” ëª¨ë“ˆì…ë‹ˆë‹¤.
    # fix_training_data.pyì—ì„œ importí•˜ì—¬ ì‚¬ìš©í•©ë‹ˆë‹¤.
    print("ğŸ“¦ ë¼ë²¨ë³„ ìºì‹± ì‹œìŠ¤í…œ ëª¨ë“ˆ ë¡œë“œ ì™„ë£Œ") 