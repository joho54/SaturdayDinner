import pandas as pd
import numpy as np
from collections import defaultdict, Counter
import json
import warnings
import random
warnings.filterwarnings('ignore')

class ImprovedCrossCategorizer:
    def __init__(self, max_chapters=4):
        self.max_chapters = max_chapters
        self.label_cluster_data = None
        self.video_cluster_data = None
        self.merged_data = None
        self.chapters = {}
        self.adjacency = None
        
    def load_data(self, label_cluster_file, video_cluster_file):
        """ë°ì´í„° ë¡œë“œ ë° ì „ì²˜ë¦¬"""
        self.label_cluster_data = pd.read_csv(label_cluster_file)
        print(f"ë¼ë²¨ í´ëŸ¬ìŠ¤í„° ë°ì´í„° ë¡œë“œ: {len(self.label_cluster_data)} í–‰")
        
        self.video_cluster_data = pd.read_csv(video_cluster_file)
        print(f"ë¹„ë””ì˜¤ í´ëŸ¬ìŠ¤í„° ë°ì´í„° ë¡œë“œ: {len(self.video_cluster_data)} í–‰")
        
        self._merge_data()
        
    def _merge_data(self):
        """ë‘ ë°ì´í„°ì…‹ì„ ë³‘í•©"""
        label_data = self.label_cluster_data.copy()
        video_data = self.video_cluster_data.copy()
        
        label_data['filename_normalized'] = label_data['íŒŒì¼ëª…'].str.replace(r'\.(MOV|AVI|MP4|MTS)$', '', regex=True)
        video_data['filename_normalized'] = video_data['filename'].str.replace(r'\.(MOV|AVI|MP4|MTS)$', '', regex=True)
        
        self.merged_data = pd.merge(
            label_data[['filename_normalized', 'í•œêµ­ì–´', 'í´ëŸ¬ìŠ¤í„°_ID', 'í´ëŸ¬ìŠ¤í„°_í¬ê¸°']],
            video_data[['filename_normalized', 'cluster_id']],
            on='filename_normalized',
            how='inner'
        )
        
        print(f"ë³‘í•©ëœ ë°ì´í„°: {len(self.merged_data)} í–‰")
        
        self.label_info = {}
        for _, row in self.merged_data.iterrows():
            label = row['í•œêµ­ì–´']
            if label not in self.label_info:
                self.label_info[label] = {
                    'natural_cluster': row['í´ëŸ¬ìŠ¤í„°_ID'],
                    'video_cluster': row['cluster_id']
                }
        
        print(f"ê³ ìœ  ë¼ë²¨ ìˆ˜: {len(self.label_info)}")
        
    def build_constraint_graph(self):
        """ì œì•½ ì¡°ê±´ì„ ê¸°ë°˜ìœ¼ë¡œ ê·¸ë˜í”„ êµ¬ì¶•"""
        print("\nì œì•½ ì¡°ê±´ ê·¸ë˜í”„ êµ¬ì¶•...")
        
        natural_clusters = defaultdict(list)
        video_clusters = defaultdict(list)
        
        for label, info in self.label_info.items():
            natural_clusters[info['natural_cluster']].append(label)
            video_clusters[info['video_cluster']].append(label)
        
        # ì¸ì ‘ ë¦¬ìŠ¤íŠ¸ ìƒì„±
        all_labels = list(self.label_info.keys())
        self.adjacency = {label: set() for label in all_labels}
        
        # ë¹„ë””ì˜¤ í´ëŸ¬ìŠ¤í„° ì œì•½ ì¡°ê±´: ê°™ì€ ë¹„ë””ì˜¤ í´ëŸ¬ìŠ¤í„°ì˜ ë¼ë²¨ë“¤ì€ ì„œë¡œ ì¸ì ‘
        conflict_edges = 0
        for video_cluster_id, video_labels in video_clusters.items():
            for i in range(len(video_labels)):
                for j in range(i + 1, len(video_labels)):
                    self.adjacency[video_labels[i]].add(video_labels[j])
                    self.adjacency[video_labels[j]].add(video_labels[i])
                    conflict_edges += 1
        
        print(f"ì¶©ëŒ ì—£ì§€ ìˆ˜: {conflict_edges}")
        print(f"ìì—°ì–´ í´ëŸ¬ìŠ¤í„° ìˆ˜: {len(natural_clusters)}")
        print(f"ë¹„ë””ì˜¤ í´ëŸ¬ìŠ¤í„° ìˆ˜: {len(video_clusters)}")
        
        return natural_clusters, video_clusters
    
    def greedy_coloring_with_priorities(self, natural_clusters):
        """ìš°ì„ ìˆœìœ„ë¥¼ ê³ ë ¤í•œ íƒìš•ì  ìƒ‰ì¹  ì•Œê³ ë¦¬ì¦˜"""
        print("\nìš°ì„ ìˆœìœ„ ê¸°ë°˜ íƒìš•ì  ìƒ‰ì¹  ì‹œì‘...")
        
        # ì°¨ìˆ˜ ê³„ì‚°
        degree_dict = {label: len(neighbors) for label, neighbors in self.adjacency.items()}
        
        # ìì—°ì–´ í´ëŸ¬ìŠ¤í„° í¬ê¸° ê³„ì‚°
        natural_cluster_sizes = {}
        for cluster_id, labels in natural_clusters.items():
            for label in labels:
                natural_cluster_sizes[label] = len(labels)
        
        # ìš°ì„ ìˆœìœ„: ì°¨ìˆ˜ê°€ ë†’ê³ , ìì—°ì–´ í´ëŸ¬ìŠ¤í„°ê°€ ì‘ì€ ë¼ë²¨ë¶€í„° ì²˜ë¦¬
        def priority_score(label):
            degree = degree_dict.get(label, 0)
            cluster_size = natural_cluster_sizes.get(label, 1)
            return (degree, -cluster_size)
        
        sorted_labels = sorted(self.label_info.keys(), key=priority_score, reverse=True)
        
        # ìƒ‰ì¹  ìˆ˜í–‰
        coloring = {}
        
        for label in sorted_labels:
            # ì¸ì ‘í•œ ë…¸ë“œë“¤ì˜ ìƒ‰ê¹” í™•ì¸
            used_colors = set()
            for neighbor in self.adjacency[label]:
                if neighbor in coloring:
                    used_colors.add(coloring[neighbor])
            
            # ì‚¬ìš© ê°€ëŠ¥í•œ ìƒ‰ê¹” ì°¾ê¸°
            for color in range(self.max_chapters):
                if color not in used_colors:
                    coloring[label] = color
                    break
            else:
                # ì‚¬ìš© ê°€ëŠ¥í•œ ìƒ‰ê¹”ì´ ì—†ëŠ” ê²½ìš° - ê°€ì¥ ì ê²Œ ì‚¬ìš©ëœ ìƒ‰ê¹” í• ë‹¹
                color_counts = Counter(coloring.values())
                min_color = min(range(self.max_chapters), key=lambda c: color_counts.get(c, 0))
                coloring[label] = min_color
                print(f"âš ï¸ ë¼ë²¨ '{label}'ì— ê°•ì œë¡œ ìƒ‰ê¹” {min_color} í• ë‹¹")
        
        return coloring
    
    def improve_with_natural_clusters(self, coloring, natural_clusters):
        """ìì—°ì–´ í´ëŸ¬ìŠ¤í„° ì‘ì§‘ë„ë¥¼ ê°œì„ """
        print("\nìì—°ì–´ í´ëŸ¬ìŠ¤í„° ì‘ì§‘ë„ ê°œì„ ...")
        
        improved_coloring = coloring.copy()
        improvements = 0
        
        for cluster_id, cluster_labels in natural_clusters.items():
            if len(cluster_labels) <= 1:
                continue
                
            # í˜„ì¬ í´ëŸ¬ìŠ¤í„°ì˜ ìƒ‰ê¹” ë¶„í¬ í™•ì¸
            color_counts = Counter()
            for label in cluster_labels:
                if label in improved_coloring:
                    color_counts[improved_coloring[label]] += 1
            
            if not color_counts:
                continue
                
            # ê°€ì¥ ë§ì´ ì‚¬ìš©ëœ ìƒ‰ê¹”
            target_color = color_counts.most_common(1)[0][0]
            
            # ë‹¤ë¥¸ ìƒ‰ê¹”ì˜ ë¼ë²¨ë“¤ì„ target_colorë¡œ ë³€ê²½ ì‹œë„
            for label in cluster_labels:
                if label not in improved_coloring:
                    continue
                    
                current_color = improved_coloring[label]
                if current_color == target_color:
                    continue
                
                # target_colorë¡œ ë³€ê²½ ê°€ëŠ¥í•œì§€ í™•ì¸
                can_change = True
                for neighbor in self.adjacency[label]:
                    if neighbor in improved_coloring and improved_coloring[neighbor] == target_color:
                        can_change = False
                        break
                
                if can_change:
                    improved_coloring[label] = target_color
                    improvements += 1
        
        print(f"ê°œì„ ëœ í• ë‹¹ ìˆ˜: {improvements}")
        return improved_coloring
    
    def evaluate_coloring(self, coloring, natural_clusters):
        """ìƒ‰ì¹  ê²°ê³¼ í‰ê°€"""
        # ì œì•½ ì¡°ê±´ ìœ„ë°˜ ê³„ì‚°
        violations = 0
        for label, neighbors in self.adjacency.items():
            if label in coloring:
                for neighbor in neighbors:
                    if neighbor in coloring and coloring[label] == coloring[neighbor]:
                        violations += 1
        violations //= 2  # ê° ìœ„ë°˜ì´ ë‘ ë²ˆ ê³„ì‚°ë˜ë¯€ë¡œ
        
        # ìì—°ì–´ í´ëŸ¬ìŠ¤í„° ì‘ì§‘ë„ ê³„ì‚°
        cohesion_score = 0
        total_clusters = 0
        
        for cluster_id, cluster_labels in natural_clusters.items():
            if len(cluster_labels) <= 1:
                continue
                
            color_counts = Counter()
            for label in cluster_labels:
                if label in coloring:
                    color_counts[coloring[label]] += 1
            
            if color_counts:
                max_count = max(color_counts.values())
                total_count = sum(color_counts.values())
                cohesion = max_count / total_count
                cohesion_score += cohesion
                total_clusters += 1
        
        avg_cohesion = cohesion_score / total_clusters if total_clusters > 0 else 0
        
        # ì „ì²´ ì ìˆ˜
        score = avg_cohesion - violations * 0.01
        return score, violations, avg_cohesion
    
    def create_chapters(self):
        """ê°œì„ ëœ ì±•í„° ìƒì„± ì•Œê³ ë¦¬ì¦˜"""
        natural_clusters, video_clusters = self.build_constraint_graph()
        
        # 1ë‹¨ê³„: íƒìš•ì  ìƒ‰ì¹ 
        coloring = self.greedy_coloring_with_priorities(natural_clusters)
        
        # 2ë‹¨ê³„: ìì—°ì–´ í´ëŸ¬ìŠ¤í„° ì‘ì§‘ë„ ê°œì„ 
        coloring = self.improve_with_natural_clusters(coloring, natural_clusters)
        
        # ì„±ëŠ¥ í‰ê°€
        score, violations, cohesion = self.evaluate_coloring(coloring, natural_clusters)
        print(f"ìµœì¢… ì ìˆ˜: {score:.3f} (ìœ„ë°˜: {violations}, ì‘ì§‘ë„: {cohesion:.3f})")
        
        # ì±•í„° ë”•ì…”ë„ˆë¦¬ ìƒì„±
        chapters = defaultdict(list)
        for label, chapter_id in coloring.items():
            chapters[chapter_id].append(label)
        
        self.chapters = {f"ì±•í„°_{i}": labels for i, labels in chapters.items()}
        
        # ë¹ˆ ì±•í„°ê°€ ìˆìœ¼ë©´ ì¶”ê°€
        while len(self.chapters) < self.max_chapters:
            empty_chapter_id = len(self.chapters)
            self.chapters[f"ì±•í„°_{empty_chapter_id}"] = []
        
        return self.chapters
    
    def validate_constraints(self):
        """ì œì•½ ì¡°ê±´ ê²€ì¦"""
        print("\nì œì•½ ì¡°ê±´ ê²€ì¦...")
        
        label_to_chapter = {}
        for chapter_name, labels in self.chapters.items():
            for label in labels:
                label_to_chapter[label] = chapter_name
        
        violations = 0
        
        # ì¸ì ‘í•œ ë¼ë²¨ë“¤ì´ ê°™ì€ ì±•í„°ì— ìˆëŠ”ì§€ í™•ì¸
        for label, neighbors in self.adjacency.items():
            if label in label_to_chapter:
                for neighbor in neighbors:
                    if neighbor in label_to_chapter and label_to_chapter[label] == label_to_chapter[neighbor]:
                        violations += 1
        violations //= 2  # ê° ìœ„ë°˜ì´ ë‘ ë²ˆ ê³„ì‚°ë˜ë¯€ë¡œ
        
        # ìì—°ì–´ í´ëŸ¬ìŠ¤í„° ì‘ì§‘ë„ ë¶„ì„
        natural_clusters = defaultdict(list)
        for label, info in self.label_info.items():
            natural_clusters[info['natural_cluster']].append(label)
        
        natural_cohesion = []
        for natural_cluster_id, natural_labels in natural_clusters.items():
            if len(natural_labels) <= 1:
                continue
                
            chapter_distribution = defaultdict(int)
            for label in natural_labels:
                if label in label_to_chapter:
                    chapter_distribution[label_to_chapter[label]] += 1
            
            if chapter_distribution:
                max_in_one_chapter = max(chapter_distribution.values())
                cohesion = max_in_one_chapter / len(natural_labels)
                natural_cohesion.append(cohesion)
        
        avg_cohesion = np.mean(natural_cohesion) if natural_cohesion else 0
        
        print(f"ì œì•½ ì¡°ê±´ ìœ„ë°˜ ìˆ˜: {violations}")
        print(f"ìì—°ì–´ í´ëŸ¬ìŠ¤í„° í‰ê·  ì‘ì§‘ë„: {avg_cohesion:.3f}")
        print(f"í• ë‹¹ëœ ë¼ë²¨ ìˆ˜: {len(label_to_chapter)}/{len(self.label_info)}")
        
        return violations == 0, violations, avg_cohesion
    
    def generate_output(self):
        """ìµœì¢… ê²°ê³¼ ìƒì„±"""
        label_dict = {}
        label_id = 0
        
        for chapter_name, labels in self.chapters.items():
            for label in labels:
                label_dict[label] = label_id
                label_id += 1
        
        # None ì¶”ê°€
        label_dict["None"] = label_id
        
        # ì œì•½ ì¡°ê±´ ê²€ì¦
        is_valid, violations, avg_cohesion = self.validate_constraints()
        
        result = {
            "label_dict": label_dict,
            "chapters": self.chapters,
            "summary": {
                "total_labels": len(self.label_info),
                "assigned_labels": len(label_dict) - 1,
                "assignment_rate": (len(label_dict) - 1) / len(self.label_info) * 100,
                "total_chapters": len([ch for ch in self.chapters.keys() if len(self.chapters[ch]) > 0]),
                "chapter_sizes": {name: len(labels) for name, labels in self.chapters.items()},
                "constraint_violations": violations,
                "natural_cluster_cohesion": avg_cohesion,
                "constraints_satisfied": is_valid
            }
        }
        
        return result

def main():
    categorizer = ImprovedCrossCategorizer(max_chapters=4)
    
    categorizer.load_data(
        'clustered_labels_with_filenames.csv',
        'clustering_results_20250702_195813.csv'
    )
    
    chapters = categorizer.create_chapters()
    result = categorizer.generate_output()
    
    print("\n" + "="*60)
    print("ê°œì„ ëœ ì±•í„° ìƒì„± ê²°ê³¼")
    print("="*60)
    
    for chapter_name, labels in result["chapters"].items():
        if not labels:
            continue
            
        print(f"\n{chapter_name} ({len(labels)}ê°œ ë¼ë²¨):")
        
        # ìì—°ì–´ í´ëŸ¬ìŠ¤í„°ë³„ë¡œ ê·¸ë£¹í™”í•˜ì—¬ í‘œì‹œ
        label_groups = defaultdict(list)
        for label in labels:
            if label in categorizer.label_info:
                cluster_id = categorizer.label_info[label]['natural_cluster']
                label_groups[cluster_id].append(label)
        
        for cluster_id, cluster_labels in list(label_groups.items())[:3]:  # ì²˜ìŒ 3ê°œ í´ëŸ¬ìŠ¤í„°ë§Œ
            print(f"  [ìì—°ì–´ í´ëŸ¬ìŠ¤í„° {cluster_id}] ({len(cluster_labels)}ê°œ):")
            for label in cluster_labels[:3]:  # ì²˜ìŒ 3ê°œ ë¼ë²¨ë§Œ
                print(f"    - {label}")
            if len(cluster_labels) > 3:
                print(f"    ...")
        
        if len(label_groups) > 3:
            print(f"  ... (ì´ {len(label_groups)}ê°œ ìì—°ì–´ í´ëŸ¬ìŠ¤í„°)")
    
    summary = result["summary"]
    print(f"\nğŸ“Š ìš”ì•½:")
    print(f"  â€¢ ì „ì²´ ë¼ë²¨ ìˆ˜: {summary['total_labels']}")
    print(f"  â€¢ í• ë‹¹ëœ ë¼ë²¨ ìˆ˜: {summary['assigned_labels']}")
    print(f"  â€¢ í• ë‹¹ ë¹„ìœ¨: {summary['assignment_rate']:.1f}%")
    print(f"  â€¢ í™œì„± ì±•í„° ìˆ˜: {summary['total_chapters']}")
    print(f"  â€¢ ì œì•½ ì¡°ê±´ ìœ„ë°˜: {summary['constraint_violations']}ê°œ")
    print(f"  â€¢ ìì—°ì–´ í´ëŸ¬ìŠ¤í„° ì‘ì§‘ë„: {summary['natural_cluster_cohesion']:.3f}")
    print(f"  â€¢ ì œì•½ ì¡°ê±´ ë§Œì¡±: {'âœ…' if summary['constraints_satisfied'] else 'âŒ'}")
    
    with open('improved_chapter_result.json', 'w', encoding='utf-8') as f:
        json.dump(result, f, ensure_ascii=False, indent=2)
    print(f"\nğŸ’¾ ê²°ê³¼ê°€ 'improved_chapter_result.json'ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")
    
    return result

if __name__ == "__main__":
    result = main() 