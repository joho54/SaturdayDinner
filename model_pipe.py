#!/usr/bin/env python3
"""
ìˆ˜ì–´ ì¸ì‹ ëª¨ë¸ í•™ìŠµ íŒŒì´í”„ë¼ì¸
ì‚¬ìš©ë²•: python3 model_pipe.py spec.json
"""

import os
import sys
import json
import csv
import cv2
import numpy as np
import mediapipe as mp
from tqdm import tqdm
from sklearn.model_selection import train_test_split
import tensorflow as tf
from tensorflow.keras.models import Model
from tensorflow.keras.layers import (
    LSTM,
    Dense,
    Dropout,
    Input,
    Bidirectional,
    Conv1D,
    MaxPooling1D,
    GlobalAveragePooling1D,
    LayerNormalization,
    MultiHeadAttention,
    Add,
)
from tensorflow.keras.utils import to_categorical
from scipy.interpolate import interp1d
import datetime
import random

# MediaPipe ì´ˆê¸°í™”
mp_holistic = mp.solutions.holistic
holistic = mp_holistic.Holistic()

# ê²½ë¡œ ì„¤ì • (ë³€ìˆ˜ë¡œ ìƒì„±í•˜ì—¬ ê²½ë¡œ ë³€ê²½ ê°€ëŠ¥)
VIDEO_ROOT1 = "/Volumes/Sub_Storage/ìˆ˜ì–´ ë°ì´í„°ì…‹/ìˆ˜ì–´ ë°ì´í„°ì…‹/0001~3000(ì˜ìƒ)"
VIDEO_ROOT2 = "/Volumes/Sub_Storage/ìˆ˜ì–´ ë°ì´í„°ì…‹/ìˆ˜ì–´ ë°ì´í„°ì…‹/3001~6000(ì˜ìƒ)"
VIDEO_ROOT3 = "/Volumes/Sub_Storage/ìˆ˜ì–´ ë°ì´í„°ì…‹/ìˆ˜ì–´ ë°ì´í„°ì…‹/6001~8280(ì˜ìƒ)"
VIDEO_ROOT4 = "/Volumes/Sub_Storage/ìˆ˜ì–´ ë°ì´í„°ì…‹/ìˆ˜ì–´ ë°ì´í„°ì…‹/8381~9000(ì˜ìƒ)"
VIDEO_ROOT5 = "/Volumes/Sub_Storage/ìˆ˜ì–´ ë°ì´í„°ì…‹/ìˆ˜ì–´ ë°ì´í„°ì…‹/9001~9600(ì˜ìƒ)"

# CSV íŒŒì¼ ê²½ë¡œ (ë³€ìˆ˜ë¡œ ìƒì„±)
LABEL_CSV_PATH = "./labels.csv"

def load_spec(spec_path):
    """spec.json íŒŒì¼ì„ ë¡œë“œí•©ë‹ˆë‹¤."""
    try:
        with open(spec_path, 'r', encoding='utf-8') as f:
            return json.load(f)
    except FileNotFoundError:
        print(f"âŒ ì˜¤ë¥˜: {spec_path} íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        sys.exit(1)
    except json.JSONDecodeError:
        print(f"âŒ ì˜¤ë¥˜: {spec_path} íŒŒì¼ì˜ JSON í˜•ì‹ì´ ì˜¬ë°”ë¥´ì§€ ì•ŠìŠµë‹ˆë‹¤.")
        sys.exit(1)

def load_label_csv(csv_path):
    """label.csv íŒŒì¼ì„ ë¡œë“œí•˜ì—¬ ë”•ì…”ë„ˆë¦¬ë¡œ ë³€í™˜í•©ë‹ˆë‹¤."""
    label_dict = {}
    try:
        with open(csv_path, 'r', encoding='utf-8') as f:
            reader = csv.DictReader(f)
            for row in reader:
                label_dict[row['filename']] = row['label']
        print(f"âœ… {len(label_dict)}ê°œì˜ ë¼ë²¨ ë°ì´í„°ë¥¼ ë¡œë“œí–ˆìŠµë‹ˆë‹¤.")
        return label_dict
    except FileNotFoundError:
        print(f"âŒ ì˜¤ë¥˜: {csv_path} íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        sys.exit(1)

def filter_labels_by_spec(label_dict, target_labels):
    """spec.jsonì— ëª…ì‹œëœ ë¼ë²¨ê³¼ ì¼ì¹˜í•˜ëŠ” ì˜ìƒ:ë¼ë²¨ ìŒë§Œ í•„í„°ë§í•©ë‹ˆë‹¤."""
    filtered_dict = {}
    for filename, label in label_dict.items():
        if label in target_labels:
            filtered_dict[filename] = label
    
    print(f"âœ… í•„í„°ë§ ê²°ê³¼: {len(filtered_dict)}ê°œì˜ ì˜ìƒì´ ì„ íƒë˜ì—ˆìŠµë‹ˆë‹¤.")
    for label in target_labels:
        count = sum(1 for l in filtered_dict.values() if l == label)
        print(f"   - {label}: {count}ê°œ")
    
    return filtered_dict

def get_video_root_and_path(filename):
    """íŒŒì¼ëª…ì—ì„œ ë²ˆí˜¸ë¥¼ ì¶”ì¶œí•´ ì˜¬ë°”ë¥¸ VIDEO_ROOT ê²½ë¡œì™€ ì‹¤ì œ íŒŒì¼ ê²½ë¡œë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤."""
    try:
        num_str = filename.split("_")[-1].split(".")[0]
        num = int(num_str)
    except Exception:
        return None

    if 1 <= num <= 3000:
        root = VIDEO_ROOT1
    elif 3001 <= num <= 6000:
        root = VIDEO_ROOT2
    elif 6001 <= num <= 8280:
        root = VIDEO_ROOT3
    elif 8381 <= num <= 9000:
        root = VIDEO_ROOT4
    elif 9001 <= num <= 9600:
        root = VIDEO_ROOT5
    else:
        return None

    base_name = "_".join(filename.split("_")[:-1]) + f"_{num_str}"
    for ext in [".MOV", ".MTS", ".AVI", ".MP4"]:
        # ëŒ€ë¬¸ìì™€ ì†Œë¬¸ì ëª¨ë‘ ì‹œë„
        for case_ext in [ext, ext.lower()]:
            candidate = os.path.join(root, base_name + case_ext)
            if os.path.exists(candidate):
                return candidate
    return None

def normalize_sequence_length(sequence, target_length=30):
    """ì‹œí€€ìŠ¤ ê¸¸ì´ë¥¼ ì •ê·œí™”í•©ë‹ˆë‹¤."""
    current_length = len(sequence)

    if current_length == target_length:
        return sequence

    x_old = np.linspace(0, 1, current_length)
    x_new = np.linspace(0, 1, target_length)

    normalized_sequence = []
    for i in range(sequence.shape[1]):
        f = interp1d(
            x_old,
            sequence[:, i],
            kind="linear",
            bounds_error=False,
            fill_value="extrapolate",
        )
        normalized_sequence.append(f(x_new))

    return np.array(normalized_sequence).T

def convert_to_relative_coordinates(landmarks_list):
    """ì ˆëŒ€ ì¢Œí‘œë¥¼ ì–´ê¹¨ ì¤‘ì‹¬ ìƒëŒ€ ì¢Œí‘œê³„ë¡œ ë³€í™˜í•©ë‹ˆë‹¤."""
    relative_landmarks = []

    for frame in landmarks_list:
        if not frame["pose"]:
            relative_landmarks.append(frame)
            continue

        pose_landmarks = frame["pose"].landmark

        left_shoulder = pose_landmarks[11]
        right_shoulder = pose_landmarks[12]
        shoulder_center_x = (left_shoulder.x + right_shoulder.x) / 2
        shoulder_center_y = (left_shoulder.y + right_shoulder.y) / 2
        shoulder_center_z = (left_shoulder.z + right_shoulder.z) / 2

        shoulder_width = abs(right_shoulder.x - left_shoulder.x)
        if shoulder_width == 0:
            shoulder_width = 1.0

        new_frame = {}

        if frame["pose"]:
            relative_pose = []
            for landmark in pose_landmarks:
                rel_x = (landmark.x - shoulder_center_x) / shoulder_width
                rel_y = (landmark.y - shoulder_center_y) / shoulder_width
                rel_z = (landmark.z - shoulder_center_z) / shoulder_width
                relative_pose.append([rel_x, rel_y, rel_z])
            new_frame["pose"] = relative_pose

        for hand_key in ["left_hand", "right_hand"]:
            if frame[hand_key]:
                relative_hand = []
                for landmark in frame[hand_key].landmark:
                    rel_x = (landmark.x - shoulder_center_x) / shoulder_width
                    rel_y = (landmark.y - shoulder_center_y) / shoulder_width
                    rel_z = (landmark.z - shoulder_center_z) / shoulder_width
                    relative_hand.append([rel_x, rel_y, rel_z])
                new_frame[hand_key] = relative_hand
            else:
                new_frame[hand_key] = None

        relative_landmarks.append(new_frame)

    return relative_landmarks

def extract_landmarks(video_path):
    """ë¹„ë””ì˜¤ì—ì„œ ëœë“œë§ˆí¬ë¥¼ ì¶”ì¶œí•©ë‹ˆë‹¤."""
    cap = cv2.VideoCapture(video_path)
    landmarks_list = []

    while cap.isOpened():
        ret, frame = cap.read()
        if not ret:
            break

        rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
        results = holistic.process(rgb_frame)

        frame_data = {
            "pose": results.pose_landmarks,
            "left_hand": results.left_hand_landmarks,
            "right_hand": results.right_hand_landmarks,
        }
        landmarks_list.append(frame_data)

    cap.release()
    return landmarks_list

def extract_dynamic_features(sequence):
    """ì†ë„ì™€ ê°€ì†ë„ íŠ¹ì§•ì„ ì¶”ì¶œí•©ë‹ˆë‹¤."""
    velocity = np.diff(sequence, axis=0, prepend=sequence[0:1])
    acceleration = np.diff(velocity, axis=0, prepend=velocity[0:1])
    dynamic_features = np.concatenate([sequence, velocity, acceleration], axis=1)
    return dynamic_features

def improved_preprocess_landmarks(landmarks_list, target_seq_length=30):
    """ê°œì„ ëœ ëœë“œë§ˆí¬ ì „ì²˜ë¦¬ í•¨ìˆ˜."""
    if not landmarks_list:
        return np.zeros((target_seq_length, 675))

    relative_landmarks = convert_to_relative_coordinates(landmarks_list)

    processed_frames = []
    for frame in relative_landmarks:
        combined = []
        for key in ["pose", "left_hand", "right_hand"]:
            if frame[key]:
                if isinstance(frame[key], list):
                    combined.extend(frame[key])
                else:
                    combined.extend([[l.x, l.y, l.z] for l in frame[key].landmark])
            else:
                num_points = {"pose": 33, "left_hand": 21, "right_hand": 21}[key]
                combined.extend([[0, 0, 0]] * num_points)

        if combined:
            processed_frames.append(np.array(combined).flatten())
        else:
            processed_frames.append(np.zeros(75 * 3))

    if not processed_frames:
        return np.zeros((target_seq_length, 675))

    sequence = np.array(processed_frames)

    if len(sequence) > 0:
        try:
            sequence = normalize_sequence_length(sequence, target_seq_length)
            sequence = extract_dynamic_features(sequence)

            # ì •ê·œí™” ê°œì„ : ë” ê°•í•œ ì •ê·œí™”
            sequence = (sequence - np.mean(sequence)) / (np.std(sequence) + 1e-8)

            return sequence
        except Exception as e:
            print(f"âš ï¸ ì‹œí€€ìŠ¤ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
            return np.zeros((target_seq_length, 675))

    return np.zeros((target_seq_length, 675))

def create_model(input_shape, num_classes):
    """ëª¨ë¸ì„ ìƒì„±í•©ë‹ˆë‹¤."""
    inputs = Input(shape=input_shape)
    
    # 1D Convolutional layers
    x = Conv1D(64, 3, activation='relu', padding='same')(inputs)
    x = MaxPooling1D(2)(x)
    x = Conv1D(128, 3, activation='relu', padding='same')(x)
    x = MaxPooling1D(2)(x)
    
    # LSTM layers
    x = Bidirectional(LSTM(128, return_sequences=True))(x)
    x = Dropout(0.3)(x)
    x = Bidirectional(LSTM(64, return_sequences=False))(x)
    x = Dropout(0.3)(x)
    
    # Dense layers
    x = Dense(128, activation='relu')(x)
    x = Dropout(0.3)(x)
    x = Dense(64, activation='relu')(x)
    x = Dropout(0.3)(x)
    
    outputs = Dense(num_classes, activation='softmax')(x)
    
    model = Model(inputs=inputs, outputs=outputs)
    return model

def augment_sequence(sequence, noise_level=0.05, scale_range=0.2):
    """ì‹œí€€ìŠ¤ë¥¼ ì¦ê°•í•©ë‹ˆë‹¤."""
    augmented = sequence.copy()
    
    # ë…¸ì´ì¦ˆ ì¶”ê°€
    noise = np.random.normal(0, noise_level, augmented.shape)
    augmented += noise
    
    # ìŠ¤ì¼€ì¼ë§
    scale_factor = np.random.uniform(1 - scale_range, 1 + scale_range)
    augmented *= scale_factor
    
    return augmented

def get_model_number():
    """í˜„ì¬ ì‹œê°„ì„ ê¸°ë°˜ìœ¼ë¡œ ëª¨ë¸ ë²ˆí˜¸ë¥¼ ìƒì„±í•©ë‹ˆë‹¤."""
    now = datetime.datetime.now()
    return now.strftime("%Y%m%d_%H%M%S")

def generate_cache_filename(labels, target_seq_length, augmentations_per_video):
    """ìºì‹œ íŒŒì¼ëª…ì„ ìƒì„±í•©ë‹ˆë‹¤."""
    labels_str = "_".join(sorted(labels))
    timestamp = datetime.datetime.now().strftime("%Y%m%d_%H%M%S")
    return f"landmarks_cache_{labels_str}_seq{target_seq_length}_aug{augmentations_per_video}_{timestamp}.npz"

def find_latest_cache(labels, target_seq_length, augmentations_per_video):
    """ê°€ì¥ ìµœê·¼ì˜ ìºì‹œ íŒŒì¼ì„ ì°¾ìŠµë‹ˆë‹¤."""
    npz_dir = "npzs"
    if not os.path.exists(npz_dir):
        return None
    
    labels_str = "_".join(sorted(labels))
    pattern = f"landmarks_cache_{labels_str}_seq{target_seq_length}_aug{augmentations_per_video}_*.npz"
    
    import glob
    cache_files = glob.glob(os.path.join(npz_dir, pattern))
    
    if not cache_files:
        return None
    
    # ê°€ì¥ ìµœê·¼ íŒŒì¼ ë°˜í™˜
    latest_cache = max(cache_files, key=os.path.getctime)
    return latest_cache

def load_cached_landmarks(cache_path):
    """ìºì‹œëœ ëœë“œë§ˆí¬ ë°ì´í„°ë¥¼ ë¡œë“œí•©ë‹ˆë‹¤."""
    try:
        if os.path.exists(cache_path):
            file_size_mb = os.path.getsize(cache_path) / (1024 * 1024)
            print(f"ğŸ“‚ ìºì‹œëœ ë°ì´í„° ë¡œë“œ ì¤‘: {cache_path} ({file_size_mb:.1f}MB)")
            data = np.load(cache_path, allow_pickle=True)
            X = data['X']
            y = data['y']
            filenames = data['filenames']
            
            # ë©”íƒ€ë°ì´í„° ì¶œë ¥
            if 'metadata' in data:
                metadata = data['metadata'].item()
                print(f"ğŸ“Š ìºì‹œ ë©”íƒ€ë°ì´í„°:")
                print(f"   - ë¼ë²¨: {metadata.get('labels', [])}")
                print(f"   - ì‹œí€€ìŠ¤ ê¸¸ì´: {metadata.get('sequence_length', 'N/A')}")
                print(f"   - ì¦ê°• ìˆ˜: {metadata.get('augmentations_per_video', 'N/A')}")
                print(f"   - ìƒì„±ì¼: {metadata.get('created_at', 'N/A')}")
                print(f"   - ì´ ìƒ˜í”Œ: {metadata.get('total_samples', 'N/A')}")
            
            print(f"âœ… ìºì‹œ ë¡œë“œ ì™„ë£Œ: {len(X)}ê°œ ìƒ˜í”Œ")
            return X, y, filenames
        return None, None, None
    except Exception as e:
        print(f"âš ï¸ ìºì‹œ ë¡œë“œ ì‹¤íŒ¨: {e}")
        return None, None, None

def save_cached_landmarks(X, y, filenames, cache_path, spec, target_seq_length, augmentations_per_video):
    """ëœë“œë§ˆí¬ ë°ì´í„°ë¥¼ ìºì‹œì— ì €ì¥í•©ë‹ˆë‹¤."""
    try:
        print(f"ğŸ’¾ ìºì‹œ ì €ì¥ ì¤‘: {cache_path}")
        
        # ë©”íƒ€ë°ì´í„° ì¶”ê°€
        metadata = {
            'labels': spec.get('labels', []),
            'sequence_length': target_seq_length,
            'augmentations_per_video': augmentations_per_video,
            'created_at': datetime.datetime.now().isoformat(),
            'total_samples': len(X),
            'model_name': spec.get('model_name', 'custom_model')
        }
        
        np.savez_compressed(
            cache_path, 
            X=X, 
            y=y, 
            filenames=filenames,
            metadata=metadata
        )
        print(f"âœ… ìºì‹œ ì €ì¥ ì™„ë£Œ: {len(X)}ê°œ ìƒ˜í”Œ")
    except Exception as e:
        print(f"âš ï¸ ìºì‹œ ì €ì¥ ì‹¤íŒ¨: {e}")

def save_model_info(model, model_path, spec, model_number):
    """ëª¨ë¸ ì •ë³´ë¥¼ JSON íŒŒì¼ë¡œ ì €ì¥í•©ë‹ˆë‹¤."""
    model_info = {
        "name": spec.get("model_name", "custom_model"),
        "type": "Functional",
        "total_params": model.count_params(),
        "trainable_params": model.count_params(),
        "input_shape": [None] + list(model.input_shape[1:]),
        "output_shape": [None] + list(model.output_shape[1:]),
        "layers_count": len(model.layers),
        "model_size_mb": os.path.getsize(model_path) / (1024 * 1024),
        "labels": spec.get("labels", []),
        "model_number": model_number,
        "created_at": datetime.datetime.now().isoformat()
    }
    
    # models ë””ë ‰í† ë¦¬ì— ì €ì¥
    models_dir = "models"
    os.makedirs(models_dir, exist_ok=True)
    info_path = os.path.join(models_dir, f"model-info-{model_number}.json")
    with open(info_path, 'w', encoding='utf-8') as f:
        json.dump(model_info, f, indent=2, ensure_ascii=False)
    
    print(f"âœ… ëª¨ë¸ ì •ë³´ ì €ì¥: {info_path}")

def main():
    if len(sys.argv) < 2:
        print("ì‚¬ìš©ë²•: python3 model_pipe.py spec.json [--no-cache]")
        print("  --no-cache: ìºì‹œë¥¼ ë¬´ì‹œí•˜ê³  ìƒˆë¡œ ì¶”ì¶œ")
        sys.exit(1)
    
    spec_path = sys.argv[1]
    use_cache = "--no-cache" not in sys.argv
    
    print(f"ğŸš€ ëª¨ë¸ í•™ìŠµ íŒŒì´í”„ë¼ì¸ ì‹œì‘")
    print(f"ğŸ“‹ ëª…ì„¸ íŒŒì¼: {spec_path}")
    print(f"ğŸ’¾ ìºì‹œ ì‚¬ìš©: {'ì˜ˆ' if use_cache else 'ì•„ë‹ˆì˜¤'}")
    
    # 1. spec.json ë¡œë“œ
    spec = load_spec(spec_path)
    target_labels = spec.get("labels", [])
    print(f"ğŸ¯ í•™ìŠµí•  ë¼ë²¨: {target_labels}")
    
    # 2. label.csv ë¡œë“œ
    label_dict = load_label_csv(LABEL_CSV_PATH)
    
    # 3. specì— ë§ëŠ” ë¼ë²¨ í•„í„°ë§
    filtered_dict = filter_labels_by_spec(label_dict, target_labels)
    
    if len(filtered_dict) == 0:
        print("âŒ ì˜¤ë¥˜: í•„í„°ë§ëœ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
        sys.exit(1)
    
    # 4. ì„¤ì •ê°’ ê°€ì ¸ì˜¤ê¸°
    training_config = spec.get("training_config", {})
    model_config = spec.get("model_config", {})
    
    TARGET_SEQ_LENGTH = training_config.get("sequence_length", 30)
    AUGMENTATIONS_PER_VIDEO = training_config.get("augmentations_per_video", 20)
    TEST_SPLIT = training_config.get("test_split", 0.2)
    RANDOM_STATE = training_config.get("random_state", 42)
    
    LEARNING_RATE = model_config.get("learning_rate", 0.001)
    BATCH_SIZE = model_config.get("batch_size", 32)
    EPOCHS = model_config.get("epochs", 100)
    EARLY_STOPPING_PATIENCE = model_config.get("early_stopping_patience", 10)
    
    # 5. ë°ì´í„° ì¶”ì¶œ ë° ì „ì²˜ë¦¬
    print("\nğŸ“Š ë°ì´í„° ì¶”ì¶œ ë° ì „ì²˜ë¦¬ ì¤‘...")
    
    # ìºì‹œ íŒŒì¼ ê²½ë¡œ ì„¤ì •
    npz_dir = "npzs"
    os.makedirs(npz_dir, exist_ok=True)
    
    # ìµœì‹  ìºì‹œ íŒŒì¼ ì°¾ê¸° (ìºì‹œ ì‚¬ìš©ì´ í™œì„±í™”ëœ ê²½ìš°ì—ë§Œ)
    latest_cache_path = None
    if use_cache:
        latest_cache_path = find_latest_cache(target_labels, TARGET_SEQ_LENGTH, AUGMENTATIONS_PER_VIDEO)
        if latest_cache_path:
            print(f"ğŸ“‚ ìµœì‹  ìºì‹œ íŒŒì¼ ë°œê²¬: {os.path.basename(latest_cache_path)}")
    
    # ìºì‹œëœ ë°ì´í„° í™•ì¸
    X, y, cached_filenames = load_cached_landmarks(latest_cache_path) if latest_cache_path else (None, None, None)
    
    if X is not None and use_cache:
        # ìºì‹œëœ ë°ì´í„°ê°€ ìˆìœ¼ë©´ ì‚¬ìš©
        print(f"âœ… ìºì‹œëœ ë°ì´í„° ì‚¬ìš©: {len(X)}ê°œ ìƒ˜í”Œ")
        y_one_hot = to_categorical(y, num_classes=len(target_labels))
    else:
        # ìºì‹œëœ ë°ì´í„°ê°€ ì—†ê±°ë‚˜ ìºì‹œ ì‚¬ìš©ì´ ë¹„í™œì„±í™”ëœ ê²½ìš° ìƒˆë¡œ ì¶”ì¶œ
        if not use_cache:
            print("ğŸ”„ ìºì‹œ ë¬´íš¨í™” ì˜µì…˜ì´ í™œì„±í™”ë˜ì–´ ìƒˆë¡œ ì¶”ì¶œí•©ë‹ˆë‹¤...")
        else:
            print("ğŸ”„ ìºì‹œëœ ë°ì´í„°ê°€ ì—†ì–´ ìƒˆë¡œ ì¶”ì¶œí•©ë‹ˆë‹¤...")
            
        cache_filename = generate_cache_filename(target_labels, TARGET_SEQ_LENGTH, AUGMENTATIONS_PER_VIDEO)
        cache_path = os.path.join(npz_dir, cache_filename)
        
        X = []
        y = []
        filenames = []
        
        for filename, label in tqdm(filtered_dict.items(), desc="ë°ì´í„° ì¶”ì¶œ"):
            actual_path = get_video_root_and_path(filename)
            if actual_path is None or not os.path.exists(actual_path):
                print(f"âš ï¸ íŒŒì¼ ì—†ìŒ: {filename}")
                continue

            landmarks = extract_landmarks(actual_path)
            if not landmarks:
                print(f"âš ï¸ ëœë“œë§ˆí¬ ì¶”ì¶œ ì‹¤íŒ¨: {filename}")
                continue

            processed_sequence = improved_preprocess_landmarks(landmarks, TARGET_SEQ_LENGTH)
            if processed_sequence is None or processed_sequence.shape != (TARGET_SEQ_LENGTH, 675):
                print(f"âš ï¸ ì‹œí€€ìŠ¤ í˜•íƒœ ì˜¤ë¥˜: {filename}")
                continue

            # ì›ë³¸ ë°ì´í„° ì¶”ê°€
            X.append(processed_sequence)
            y.append(target_labels.index(label))
            filenames.append(filename)

            # ì¦ê°• ë°ì´í„° ì¶”ê°€
            for _ in range(AUGMENTATIONS_PER_VIDEO):
                try:
                    augmented = augment_sequence(processed_sequence)
                    if augmented.shape == (TARGET_SEQ_LENGTH, 675):
                        X.append(augmented)
                        y.append(target_labels.index(label))
                        filenames.append(f"{filename}_aug_{_}")
                except Exception as e:
                    print(f"âš ï¸ ì¦ê°• ì¤‘ ì˜¤ë¥˜: {e}")
                    continue
        
        if len(X) == 0:
            print("âŒ ì˜¤ë¥˜: ì²˜ë¦¬ëœ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
            sys.exit(1)
        
        # ìºì‹œì— ì €ì¥
        X = np.array(X)
        y = np.array(y)
        filenames = np.array(filenames)
        save_cached_landmarks(X, y, filenames, cache_path, spec, TARGET_SEQ_LENGTH, AUGMENTATIONS_PER_VIDEO)
        
        y_one_hot = to_categorical(y, num_classes=len(target_labels))
    
    # 6. ë°ì´í„° ì¤€ë¹„
    print(f"ğŸ“Š ìµœì¢… ë°ì´í„° í†µê³„:")
    print(f"ì´ ìƒ˜í”Œ ìˆ˜: {len(X)}")
    print(f"ì…ë ¥ í˜•íƒœ: {X.shape}")
    print(f"ì¶œë ¥ í˜•íƒœ: {y_one_hot.shape}")
    
    # í´ë˜ìŠ¤ë³„ ìƒ˜í”Œ ìˆ˜ í™•ì¸
    unique, counts = np.unique(y, return_counts=True)
    for class_idx, count in zip(unique, counts):
        if 0 <= class_idx < len(target_labels):
            print(f"í´ë˜ìŠ¤ {class_idx} ({target_labels[class_idx]}): {count}ê°œ")
    
    # 7. ë°ì´í„° ë¶„í• 
    X_train, X_test, y_train, y_test = train_test_split(
        X, y_one_hot, test_size=TEST_SPLIT, random_state=RANDOM_STATE, stratify=y_one_hot
    )
    
    # 8. ëª¨ë¸ ìƒì„±
    print("\nğŸ—ï¸ ëª¨ë¸ ìƒì„± ì¤‘...")
    model = create_model(
        input_shape=(X.shape[1], X.shape[2]), 
        num_classes=len(target_labels)
    )
    
    model.compile(
        optimizer=tf.keras.optimizers.Adam(learning_rate=LEARNING_RATE),
        loss="categorical_crossentropy",
        metrics=["accuracy"],
    )
    
    print("\n--- ëª¨ë¸ êµ¬ì¡° ---")
    model.summary()
    
    # 9. ëª¨ë¸ í•™ìŠµ
    print("\nğŸ‹ï¸â€â™€ï¸ ëª¨ë¸ í•™ìŠµ ì‹œì‘...")
    
    # Early stopping ì½œë°±
    early_stopping = tf.keras.callbacks.EarlyStopping(
        monitor='val_loss',
        patience=EARLY_STOPPING_PATIENCE,
        min_delta=0.0001,  # ìµœì†Œ ê°œì„  ì„ê³„ê°’ (0.0001 = 0.01%)
        restore_best_weights=True,
        verbose=1  # Early stopping ë°œìƒ ì‹œ ë©”ì‹œì§€ ì¶œë ¥
    )
    
    # ì²´í¬í¬ì¸íŠ¸ ì½œë°±
    checkpoint_dir = "checkpoints"
    os.makedirs(checkpoint_dir, exist_ok=True)
    checkpoint_path = os.path.join(checkpoint_dir, "model-epoch-{epoch:02d}.keras")
    checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(
        checkpoint_path,
        save_best_only=True,
        monitor='val_loss'
    )
    
    # í•™ìŠµ
    history = model.fit(
        X_train, y_train,
        validation_data=(X_test, y_test),
        epochs=EPOCHS,
        batch_size=BATCH_SIZE,
        callbacks=[early_stopping, checkpoint_callback],
        verbose=1
    )
    
    # 10. ëª¨ë¸ í‰ê°€
    print("\nğŸ“ˆ ëª¨ë¸ í‰ê°€...")
    test_loss, test_accuracy = model.evaluate(X_test, y_test, verbose=0)
    print(f"í…ŒìŠ¤íŠ¸ ì •í™•ë„: {test_accuracy:.4f}")
    print(f"í…ŒìŠ¤íŠ¸ ì†ì‹¤: {test_loss:.4f}")
    
    # 11. ëª¨ë¸ ì €ì¥
    model_number = get_model_number()
    models_dir = "models"
    os.makedirs(models_dir, exist_ok=True)
    
    model_filename = f"model_{spec.get('model_name', 'custom')}_{model_number}.keras"
    model_path = os.path.join(models_dir, model_filename)
    
    model.save(model_path)
    print(f"âœ… ëª¨ë¸ ì €ì¥: {model_path}")
    
    # 12. ëª¨ë¸ ì •ë³´ ì €ì¥
    save_model_info(model, model_path, spec, model_number)
    
    print(f"\nğŸ‰ ëª¨ë¸ í•™ìŠµ ì™„ë£Œ!")
    print(f"ğŸ“ ëª¨ë¸ íŒŒì¼: {model_path}")
    print(f"ğŸ“Š ìµœì¢… ì •í™•ë„: {test_accuracy:.4f}")

if __name__ == "__main__":
    main() 