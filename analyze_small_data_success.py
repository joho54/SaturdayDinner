import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

def analyze_small_data_success_factors():
    """ì ì€ ë°ì´í„°ë¡œë„ ëª¨ë¸ì´ ì„±ê³µí•  ìˆ˜ ìˆì—ˆë˜ ì´ìœ  ë¶„ì„"""
    
    print("ğŸ” ì ì€ ë°ì´í„°(7ê°œ)ë¡œë„ ëª¨ë¸ì´ ì„±ê³µí•  ìˆ˜ ìˆì—ˆë˜ ì´ìœ  ë¶„ì„")
    print("=" * 70)
    
    # 1. ì¦ê°• íš¨ê³¼ ë¶„ì„
    print("\nğŸ“Š 1. ì¦ê°• íš¨ê³¼ ë¶„ì„")
    print("-" * 40)
    
    original_count = 7
    augmentations_per_video = 3  # í˜„ì¬ ì„¤ì •
    
    # ì¦ê°• í›„ ì´ ìƒ˜í”Œ ìˆ˜
    total_samples = original_count * (1 + augmentations_per_video)
    
    print(f"   ì›ë³¸ ë°ì´í„°: {original_count}ê°œ")
    print(f"   ì¦ê°• ìˆ˜: {augmentations_per_video}ê°œ/ë¹„ë””ì˜¤")
    print(f"   ì¦ê°• í›„ ì´ ìƒ˜í”Œ: {total_samples}ê°œ")
    print(f"   ë°ì´í„° ì¦ê°€ìœ¨: {total_samples/original_count:.1f}ë°°")
    
    # 2. ì¦ê°• ê¸°ë²•ì˜ íš¨ê³¼ì„± ë¶„ì„
    print("\nğŸ“Š 2. ì¦ê°• ê¸°ë²•ì˜ íš¨ê³¼ì„± ë¶„ì„")
    print("-" * 40)
    
    augmentation_techniques = {
        "ë…¸ì´ì¦ˆ ì¶”ê°€": {
            "level": 0.05,
            "effect": "ë¯¸ì„¸í•œ ì¢Œí‘œ ë³€í™”ë¡œ ìì—°ìŠ¤ëŸ¬ìš´ ë³€í˜•",
            "realism": "ì‹¤ì œ ìˆ˜ì–´ ë™ì‘ì˜ ìì—°ìŠ¤ëŸ¬ìš´ ë³€í˜•ê³¼ ìœ ì‚¬"
        },
        "ìŠ¤ì¼€ì¼ë§": {
            "range": 0.2,
            "effect": "í¬ê¸° ë³€í™”ë¡œ ë‹¤ì–‘í•œ ê±°ë¦¬/ê°ë„ì—ì„œì˜ ìˆ˜ì–´ ì¸ì‹",
            "realism": "ì¹´ë©”ë¼ ê±°ë¦¬ë‚˜ ê°ë„ ë³€í™” ì‹œë®¬ë ˆì´ì…˜"
        },
        "ì‹œê°„ì¶• íšŒì „": {
            "range": 0.1,
            "effect": "ì‹œê°„ì  ë³€í˜•ìœ¼ë¡œ ì†ë„ ë³€í™” ì‹œë®¬ë ˆì´ì…˜",
            "realism": "ìˆ˜ì–´ ì†ë„ë‚˜ íƒ€ì´ë° ë³€í™” ë°˜ì˜"
        }
    }
    
    for technique, details in augmentation_techniques.items():
        print(f"   {technique}:")
        for key, value in details.items():
            print(f"     {key}: {value}")
    
    # 3. ìˆ˜ì–´ ë°ì´í„°ì˜ íŠ¹ì„± ë¶„ì„
    print("\nğŸ“Š 3. ìˆ˜ì–´ ë°ì´í„°ì˜ íŠ¹ì„± ë¶„ì„")
    print("-" * 40)
    
    sign_language_characteristics = [
        "êµ¬ì¡°í™”ëœ ë™ì‘: ìˆ˜ì–´ëŠ” ì¼ì •í•œ íŒ¨í„´ê³¼ êµ¬ì¡°ë¥¼ ê°€ì§",
        "ë°˜ë³µì„±: ê°™ì€ ìˆ˜ì–´ëŠ” ë¹„ìŠ·í•œ ë™ì‘ íŒ¨í„´ì„ ë³´ì„", 
        "ëª…í™•í•œ êµ¬ë¶„: ê° ìˆ˜ì–´ëŠ” ê³ ìœ í•œ íŠ¹ì§•ì ì¸ ë™ì‘ì„ ê°€ì§",
        "ì‹œê°„ì  ì¼ê´€ì„±: ë™ì‘ì˜ ì‹œì‘-ì¤‘ê°„-ëì´ ëª…í™•í•¨",
        "ê³µê°„ì  ì œì•½: ì†ê³¼ íŒ”ì˜ ì›€ì§ì„ ë²”ìœ„ê°€ ì œí•œì "
    ]
    
    for i, characteristic in enumerate(sign_language_characteristics, 1):
        print(f"   {i}. {characteristic}")
    
    # 4. ëª¨ë¸ êµ¬ì¡°ì˜ ì í•©ì„±
    print("\nğŸ“Š 4. ëª¨ë¸ êµ¬ì¡°ì˜ ì í•©ì„±")
    print("-" * 40)
    
    model_advantages = {
        "LSTM": "ì‹œê³„ì—´ ë°ì´í„° ì²˜ë¦¬ì— ìµœì í™”",
        "Dropout": "ê³¼ì í•© ë°©ì§€ (0.3)",
        "L2 ì •ê·œí™”": "ê°€ì¤‘ì¹˜ ì œí•œìœ¼ë¡œ ì¼ë°˜í™” í–¥ìƒ",
        "ë°°ì¹˜ ì •ê·œí™”": "í•™ìŠµ ì•ˆì •ì„± í–¥ìƒ",
        "Early Stopping": "ê³¼ì í•© ì¡°ê¸° ê°ì§€"
    }
    
    for component, advantage in model_advantages.items():
        print(f"   {component}: {advantage}")
    
    # 5. ë°ì´í„° í’ˆì§ˆ ìš”ì¸
    print("\nğŸ“Š 5. ë°ì´í„° í’ˆì§ˆ ìš”ì¸")
    print("-" * 40)
    
    quality_factors = [
        "MediaPipe ëœë“œë§ˆí¬: ì •í™•í•œ í¬ì¦ˆ/ì† ì¶”ì ",
        "ì „ì²˜ë¦¬ ìµœì í™”: ìƒëŒ€ ì¢Œí‘œ ë³€í™˜ìœ¼ë¡œ ì¼ê´€ì„± í™•ë³´",
        "ì‹œí€€ìŠ¤ ì •ê·œí™”: 30í”„ë ˆì„ìœ¼ë¡œ í‘œì¤€í™”",
        "ë™ì  íŠ¹ì§• ì¶”ì¶œ: ì†ë„/ê°€ì†ë„ ì •ë³´ í¬í•¨",
        "ë…¸ì´ì¦ˆ ì œê±°: ë¶ˆí•„ìš”í•œ ì •ë³´ í•„í„°ë§"
    ]
    
    for i, factor in enumerate(quality_factors, 1):
        print(f"   {i}. {factor}")
    
    # 6. ì‹¤ì œ ì„±ê³µ ì‚¬ë¡€ ë¶„ì„
    print("\nğŸ“Š 6. ì‹¤ì œ ì„±ê³µ ì‚¬ë¡€ ë¶„ì„")
    print("-" * 40)
    
    success_cases = {
        "ì›ë³¸ 7ê°œ â†’ ì¦ê°• í›„ 28ê°œ": "4ë°° ì¦ê°€ë¡œ í•™ìŠµ ë°ì´í„° í™•ë³´",
        "êµ¬ì¡°í™”ëœ ì¦ê°•": "ì˜ë¯¸ìˆëŠ” ë³€í˜•ìœ¼ë¡œ ì¼ë°˜í™” ëŠ¥ë ¥ í–¥ìƒ",
        "ê³¼ì í•© ë°©ì§€": "ì •ê·œí™” ê¸°ë²•ìœ¼ë¡œ ì ì€ ë°ì´í„°ì—ì„œë„ ì•ˆì •ì  í•™ìŠµ",
        "íŠ¹ì§• í’ë¶€ì„±": "675ì°¨ì› íŠ¹ì§•ìœ¼ë¡œ ì¶©ë¶„í•œ ì •ë³´ ì œê³µ"
    }
    
    for case, explanation in success_cases.items():
        print(f"   {case}: {explanation}")
    
    return {
        "original_count": original_count,
        "augmented_count": total_samples,
        "augmentation_ratio": total_samples/original_count,
        "techniques": augmentation_techniques,
        "characteristics": sign_language_characteristics,
        "model_advantages": model_advantages
    }

def simulate_different_augmentation_levels():
    """ë‹¤ì–‘í•œ ì¦ê°• ìˆ˜ì¤€ì—ì„œì˜ ì„±ëŠ¥ ì˜ˆì¸¡"""
    
    print(f"\n{'='*70}")
    print("ğŸ”® ë‹¤ì–‘í•œ ì¦ê°• ìˆ˜ì¤€ì—ì„œì˜ ì„±ëŠ¥ ì˜ˆì¸¡")
    print(f"{'='*70}")
    
    original_count = 7
    augmentation_levels = [1, 3, 5, 9, 15]
    
    results = []
    
    for aug_level in augmentation_levels:
        total_samples = original_count * (1 + aug_level)
        
        # ì„±ëŠ¥ ì˜ˆì¸¡ (ê°„ë‹¨í•œ ì‹œë®¬ë ˆì´ì…˜)
        if aug_level <= 3:
            expected_performance = "ë†’ìŒ (ì ì ˆí•œ ì¦ê°•)"
            risk_level = "ë‚®ìŒ"
        elif aug_level <= 9:
            expected_performance = "ë³´í†µ (ê³¼ë„í•œ ì¦ê°• ê°€ëŠ¥ì„±)"
            risk_level = "ë³´í†µ"
        else:
            expected_performance = "ë‚®ìŒ (ê³¼ë„í•œ ì¦ê°•)"
            risk_level = "ë†’ìŒ"
        
        results.append({
            "aug_level": aug_level,
            "total_samples": total_samples,
            "performance": expected_performance,
            "risk": risk_level
        })
        
        print(f"\nğŸ“‹ ì¦ê°• ìˆ˜ì¤€: {aug_level}ê°œ/ë¹„ë””ì˜¤")
        print(f"   ì´ ìƒ˜í”Œ: {total_samples}ê°œ")
        print(f"   ì˜ˆìƒ ì„±ëŠ¥: {expected_performance}")
        print(f"   ìœ„í—˜ë„: {risk_level}")
    
    return results

def analyze_why_it_worked():
    """ì™œ ì ì€ ë°ì´í„°ë¡œë„ ì„±ê³µí–ˆëŠ”ì§€ í•µì‹¬ ìš”ì¸ ë¶„ì„"""
    
    print(f"\n{'='*70}")
    print("ğŸ¯ í•µì‹¬ ì„±ê³µ ìš”ì¸ ë¶„ì„")
    print(f"{'='*70}")
    
    key_factors = [
        {
            "factor": "ì ì ˆí•œ ì¦ê°• ì „ëµ",
            "description": "3ê°œ ì¦ê°•ì´ ê³¼ë„í•˜ì§€ ì•Šìœ¼ë©´ì„œë„ ì¶©ë¶„í•œ ë°ì´í„° ì œê³µ",
            "impact": "ë†’ìŒ"
        },
        {
            "factor": "ìˆ˜ì–´ì˜ êµ¬ì¡°í™”ëœ íŠ¹ì„±",
            "description": "ìˆ˜ì–´ëŠ” ì¼ì •í•œ íŒ¨í„´ì„ ê°€ì ¸ í•™ìŠµì´ ìƒëŒ€ì ìœ¼ë¡œ ì‰¬ì›€",
            "impact": "ë†’ìŒ"
        },
        {
            "factor": "ê³ í’ˆì§ˆ íŠ¹ì§• ì¶”ì¶œ",
            "description": "MediaPipe + ì „ì²˜ë¦¬ë¡œ 675ì°¨ì›ì˜ í’ë¶€í•œ íŠ¹ì§• ì œê³µ",
            "impact": "ë†’ìŒ"
        },
        {
            "factor": "ê³¼ì í•© ë°©ì§€ ê¸°ë²•",
            "description": "Dropout, L2 ì •ê·œí™”, Early Stoppingìœ¼ë¡œ ì•ˆì •ì  í•™ìŠµ",
            "impact": "ì¤‘ê°„"
        },
        {
            "factor": "ì ì ˆí•œ ëª¨ë¸ ë³µì¡ë„",
            "description": "LSTM ê¸°ë°˜ìœ¼ë¡œ ì‹œê³„ì—´ íŠ¹ì„±ì— ìµœì í™”",
            "impact": "ì¤‘ê°„"
        }
    ]
    
    for i, factor in enumerate(key_factors, 1):
        print(f"\n{i}. {factor['factor']}")
        print(f"   ì„¤ëª…: {factor['description']}")
        print(f"   ì˜í–¥ë„: {factor['impact']}")
    
    # í•œê³„ì  ë¶„ì„
    print(f"\n{'='*70}")
    print("âš ï¸ í•œê³„ì  ë° ì£¼ì˜ì‚¬í•­")
    print(f"{'='*70}")
    
    limitations = [
        "ì¼ë°˜í™” ëŠ¥ë ¥ ì œí•œ: ìƒˆë¡œìš´ í™˜ê²½/ê°ë„ì—ì„œ ì„±ëŠ¥ ì €í•˜ ê°€ëŠ¥",
        "ë³µì¡í•œ ìˆ˜ì–´ ì²˜ë¦¬ ì–´ë ¤ì›€: ë‹¨ìˆœí•œ ìˆ˜ì–´ì—ë§Œ ìµœì í™”",
        "ê³¼ì í•© ìœ„í—˜: ë” ë³µì¡í•œ ëª¨ë¸ì—ì„œëŠ” ì„±ëŠ¥ ì €í•˜",
        "ì‹¤ì œ ì„œë¹„ìŠ¤ í•œê³„: ì œí•œëœ ë°ì´í„°ë¡œëŠ” ì•ˆì •ì„± ë¶€ì¡±"
    ]
    
    for i, limitation in enumerate(limitations, 1):
        print(f"{i}. {limitation}")

def compare_with_other_domains():
    """ë‹¤ë¥¸ ë„ë©”ì¸ê³¼ì˜ ë¹„êµ"""
    
    print(f"\n{'='*70}")
    print("ğŸŒ ë‹¤ë¥¸ ë„ë©”ì¸ê³¼ì˜ ë¹„êµ")
    print(f"{'='*70}")
    
    domains = {
        "ìˆ˜ì–´ ì¸ì‹": {
            "data_requirement": "ë‚®ìŒ (7ê°œë¡œë„ ê°€ëŠ¥)",
            "reason": "êµ¬ì¡°í™”ëœ ë™ì‘, ëª…í™•í•œ íŒ¨í„´",
            "augmentation_effectiveness": "ë†’ìŒ"
        },
        "ì´ë¯¸ì§€ ë¶„ë¥˜": {
            "data_requirement": "ì¤‘ê°„ (ìˆ˜ë°±~ìˆ˜ì²œê°œ)",
            "reason": "ë³µì¡í•œ í…ìŠ¤ì²˜, ë‹¤ì–‘í•œ ë³€í˜•",
            "augmentation_effectiveness": "ì¤‘ê°„"
        },
        "ìì—°ì–´ ì²˜ë¦¬": {
            "data_requirement": "ë†’ìŒ (ìˆ˜ë§Œ~ìˆ˜ì‹­ë§Œê°œ)",
            "reason": "ë³µì¡í•œ ë¬¸ë²•, ë§¥ë½ ì˜ì¡´ì„±",
            "augmentation_effectiveness": "ë‚®ìŒ"
        }
    }
    
    for domain, info in domains.items():
        print(f"\nğŸ“‹ {domain}:")
        for key, value in info.items():
            print(f"   {key}: {value}")

if __name__ == "__main__":
    # ë©”ì¸ ë¶„ì„ ì‹¤í–‰
    analysis_result = analyze_small_data_success_factors()
    simulation_result = simulate_different_augmentation_levels()
    analyze_why_it_worked()
    compare_with_other_domains()
    
    print(f"\n{'='*70}")
    print("âœ… ë¶„ì„ ì™„ë£Œ!")
    print(f"{'='*70}")
    
    print("\nğŸ“‹ í•µì‹¬ ì¸ì‚¬ì´íŠ¸:")
    print("1. ìˆ˜ì–´ì˜ êµ¬ì¡°í™”ëœ íŠ¹ì„±ì´ ì ì€ ë°ì´í„°ë¡œë„ í•™ìŠµ ê°€ëŠ¥í•˜ê²Œ í•¨")
    print("2. ì ì ˆí•œ ì¦ê°• ì „ëµ(3ê°œ/ë¹„ë””ì˜¤)ì´ í•µì‹¬ ì„±ê³µ ìš”ì¸")
    print("3. ê³ í’ˆì§ˆ íŠ¹ì§• ì¶”ì¶œê³¼ ê³¼ì í•© ë°©ì§€ê°€ ì•ˆì •ì  ì„±ëŠ¥ ë³´ì¥")
    print("4. í•˜ì§€ë§Œ ì‹¤ì œ ì„œë¹„ìŠ¤ì—ëŠ” ë” ë§ì€ ë°ì´í„°ê°€ í•„ìš”") 