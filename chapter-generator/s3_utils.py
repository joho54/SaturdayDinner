#!/usr/bin/env python3
"""
S3 í˜¸í™˜ ìºì‹œ ì‹œìŠ¤í…œ ìœ í‹¸ë¦¬í‹°
ë¡œì»¬ íŒŒì¼ ì‹œìŠ¤í…œê³¼ S3 ë²„í‚·ì„ íˆ¬ëª…í•˜ê²Œ ì²˜ë¦¬í•  ìˆ˜ ìˆëŠ” ìºì‹œ í•¨ìˆ˜ë“¤ì„ ì œê³µí•©ë‹ˆë‹¤.
"""

import os
import pickle
import boto3
from urllib.parse import urlparse
from botocore.exceptions import ClientError, NoCredentialsError
import logging
from typing import Optional, Any, Dict

# .env íŒŒì¼ ë¡œë“œ
try:
    from dotenv import load_dotenv
    # .env íŒŒì¼ì´ ìˆëŠ” í˜„ì¬ ë””ë ‰í† ë¦¬ì—ì„œ ë¡œë“œ
    env_path = os.path.join(os.path.dirname(__file__), '.env')
    if os.path.exists(env_path):
        load_dotenv(env_path)
        print(f"âœ… .env íŒŒì¼ ë¡œë“œ: {env_path}")
    else:
        # í˜„ì¬ ì‘ì—… ë””ë ‰í† ë¦¬ì—ì„œ .env íŒŒì¼ ì°¾ê¸°
        if os.path.exists('.env'):
            load_dotenv('.env')
            print("âœ… .env íŒŒì¼ ë¡œë“œ: ./.env")
        else:
            print("âš ï¸ .env íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
except ImportError:
    print("âš ï¸ python-dotenvë¥¼ ì„¤ì¹˜í•˜ì„¸ìš”: pip install python-dotenv")

# ë¡œê¹… ì„¤ì •
logger = logging.getLogger(__name__)

class S3CacheManager:
    """S3ì™€ ë¡œì»¬ íŒŒì¼ ì‹œìŠ¤í…œì„ í†µí•©í•˜ì—¬ ê´€ë¦¬í•˜ëŠ” ìºì‹œ ë§¤ë‹ˆì €"""
    
    def __init__(self, aws_profile: str = None):
        """
        S3CacheManager ì´ˆê¸°í™”
        
        Args:
            aws_profile: AWS í”„ë¡œí•„ ì´ë¦„ (ê¸°ë³¸ê°’: None - í™˜ê²½ë³€ìˆ˜ ì‚¬ìš©)
        """
        self.aws_profile = aws_profile
        self.s3_client = None
        self._setup_s3_client()
    
    def _setup_s3_client(self):
        """S3 í´ë¼ì´ì–¸íŠ¸ ì„¤ì •"""
        # í™˜ê²½ë³€ìˆ˜ ìƒíƒœ í™•ì¸
        access_key = os.getenv('AWS_ACCESS_KEY_ID')
        secret_key = os.getenv('AWS_SECRET_ACCESS_KEY')
        region = os.getenv('AWS_DEFAULT_REGION', 'us-east-1')
        session_token = os.getenv('AWS_SESSION_TOKEN')
        
        print(f"ğŸ” AWS ìê²©ì¦ëª… ìƒíƒœ í™•ì¸:")
        print(f"  - AWS_ACCESS_KEY_ID: {'âœ… ì„¤ì •ë¨' if access_key else 'âŒ ë¯¸ì„¤ì •'}")
        print(f"  - AWS_SECRET_ACCESS_KEY: {'âœ… ì„¤ì •ë¨' if secret_key else 'âŒ ë¯¸ì„¤ì •'}")
        print(f"  - AWS_DEFAULT_REGION: {region}")
        print(f"  - AWS_SESSION_TOKEN: {'âœ… ì„¤ì •ë¨' if session_token else 'ë¯¸ì„¤ì •'}")
        
        try:
            if access_key and secret_key:
                # í™˜ê²½ë³€ìˆ˜ì—ì„œ ì§ì ‘ ìê²©ì¦ëª… ì‚¬ìš©
                session = boto3.Session(
                    aws_access_key_id=access_key,
                    aws_secret_access_key=secret_key,
                    aws_session_token=session_token,
                    region_name=region
                )
                print("âœ… í™˜ê²½ë³€ìˆ˜ì—ì„œ AWS ìê²©ì¦ëª… ì‚¬ìš©")
                logger.info("Using AWS credentials from environment variables")
            else:
                # AWS í”„ë¡œí•„ ì‚¬ìš©
                session = boto3.Session(profile_name=self.aws_profile)
                print(f"âœ… AWS í”„ë¡œí•„ ì‚¬ìš©: {self.aws_profile}")
                logger.info(f"Using AWS profile: {self.aws_profile}")
            
            self.s3_client = session.client('s3')
            print("âœ… S3 í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” ì„±ê³µ")
            logger.info("S3 client initialized successfully")
            
        except NoCredentialsError as e:
            print(f"âŒ AWS ìê²©ì¦ëª… ì˜¤ë¥˜: {e}")
            print("ğŸ’¡ í•´ê²°ë°©ë²•:")
            print("  1. .env íŒŒì¼ì— AWS_ACCESS_KEY_ID, AWS_SECRET_ACCESS_KEY ì„¤ì •")
            print("  2. ë˜ëŠ” AWS CLIë¡œ í”„ë¡œí•„ ì„¤ì •: aws configure")
            logger.warning(f"S3 client initialization failed: {e}")
            self.s3_client = None
        except Exception as e:
            print(f"âŒ S3 í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
            logger.warning(f"S3 client initialization failed: {e}")
            self.s3_client = None
    
    def is_s3_path(self, path: str) -> bool:
        """ê²½ë¡œê°€ S3 ê²½ë¡œì¸ì§€ í™•ì¸"""
        return path.startswith('s3://')
    
    def parse_s3_path(self, s3_path: str) -> tuple:
        """S3 ê²½ë¡œë¥¼ ë²„í‚·ê³¼ í‚¤ë¡œ ë¶„ë¦¬"""
        parsed = urlparse(s3_path)
        bucket = parsed.netloc
        key = parsed.path.lstrip('/')
        return bucket, key
    
    def join_path(self, base_path: str, *parts: str) -> str:
        """ê²½ë¡œ ì¡°í•© (S3/ë¡œì»¬ í˜¸í™˜)"""
        if self.is_s3_path(base_path):
            # S3 ê²½ë¡œì¸ ê²½ìš° '/'ë¡œ ì¡°í•©
            path = base_path.rstrip('/')
            for part in parts:
                path += '/' + str(part).strip('/')
            return path
        else:
            # ë¡œì»¬ ê²½ë¡œì¸ ê²½ìš° os.path.join ì‚¬ìš©
            return os.path.join(base_path, *parts)
    
    def exists(self, path: str) -> bool:
        """íŒŒì¼/ê°ì²´ ì¡´ì¬ ì—¬ë¶€ í™•ì¸"""
        if self.is_s3_path(path):
            if not self.s3_client:
                logger.warning("S3 client not available, assuming file doesn't exist")
                return False
            
            try:
                bucket, key = self.parse_s3_path(path)
                self.s3_client.head_object(Bucket=bucket, Key=key)
                return True
            except ClientError as e:
                error_code = e.response['Error']['Code']
                if error_code == '404':
                    return False
                else:
                    logger.error(f"S3 error checking {path}: {e}")
                    return False
            except Exception as e:
                logger.error(f"Error checking S3 path {path}: {e}")
                return False
        else:
            return os.path.exists(path)
    
    def makedirs(self, path: str, exist_ok: bool = True):
        """ë””ë ‰í† ë¦¬ ìƒì„± (S3ì—ì„œëŠ” ë¶ˆí•„ìš”í•˜ë¯€ë¡œ ê±´ë„ˆëœ€)"""
        if self.is_s3_path(path):
            # S3ì—ì„œëŠ” ë””ë ‰í† ë¦¬ ìƒì„±ì´ ë¶ˆí•„ìš”
            logger.debug(f"S3 path detected, skipping makedirs for {path}")
            return
        else:
            os.makedirs(path, exist_ok=exist_ok)
    
    def save_pickle(self, path: str, data: Any) -> bool:
        """í”¼í´ ë°ì´í„° ì €ì¥"""
        try:
            if self.is_s3_path(path):
                if not self.s3_client:
                    logger.error("S3 client not available for saving")
                    return False
                
                # ë©”ëª¨ë¦¬ì—ì„œ í”¼í´ ì§ë ¬í™”
                pickle_data = pickle.dumps(data, protocol=pickle.HIGHEST_PROTOCOL)
                
                # S3ì— ì—…ë¡œë“œ
                bucket, key = self.parse_s3_path(path)
                self.s3_client.put_object(
                    Bucket=bucket,
                    Key=key,
                    Body=pickle_data,
                    ContentType='application/octet-stream'
                )
                logger.info(f"Saved pickle to S3: {path}")
                return True
            else:
                # ë¡œì»¬ íŒŒì¼ë¡œ ì €ì¥
                # ì„ì‹œ íŒŒì¼ ë°©ì‹ìœ¼ë¡œ ì›ìì  ì“°ê¸°
                temp_path = path + ".tmp"
                with open(temp_path, "wb") as f:
                    pickle.dump(data, f, protocol=pickle.HIGHEST_PROTOCOL)
                os.replace(temp_path, path)
                logger.info(f"Saved pickle to local: {path}")
                return True
                
        except Exception as e:
            logger.error(f"Error saving pickle to {path}: {e}")
            return False
    
    def load_pickle(self, path: str) -> Optional[Any]:
        """í”¼í´ ë°ì´í„° ë¡œë“œ"""
        try:
            if self.is_s3_path(path):
                if not self.s3_client:
                    logger.error("S3 client not available for loading")
                    return None
                
                # S3ì—ì„œ ë‹¤ìš´ë¡œë“œ
                bucket, key = self.parse_s3_path(path)
                response = self.s3_client.get_object(Bucket=bucket, Key=key)
                pickle_data = response['Body'].read()
                
                # í”¼í´ ì—­ì§ë ¬í™”
                data = pickle.loads(pickle_data)
                logger.info(f"Loaded pickle from S3: {path}")
                return data
            else:
                # ë¡œì»¬ íŒŒì¼ì—ì„œ ë¡œë“œ
                with open(path, "rb") as f:
                    data = pickle.load(f)
                logger.info(f"Loaded pickle from local: {path}")
                return data
                
        except ClientError as e:
            error_code = e.response['Error']['Code']
            if error_code == 'NoSuchKey':
                logger.debug(f"S3 object not found: {path}")
            else:
                logger.error(f"S3 error loading {path}: {e}")
            return None
        except FileNotFoundError:
            logger.debug(f"Local file not found: {path}")
            return None
        except Exception as e:
            logger.error(f"Error loading pickle from {path}: {e}")
            return None
    
    def remove(self, path: str) -> bool:
        """íŒŒì¼/ê°ì²´ ì‚­ì œ"""
        try:
            if self.is_s3_path(path):
                if not self.s3_client:
                    logger.error("S3 client not available for deletion")
                    return False
                
                bucket, key = self.parse_s3_path(path)
                self.s3_client.delete_object(Bucket=bucket, Key=key)
                logger.info(f"Deleted S3 object: {path}")
                return True
            else:
                if os.path.exists(path):
                    os.remove(path)
                    logger.info(f"Deleted local file: {path}")
                return True
                
        except Exception as e:
            logger.error(f"Error deleting {path}: {e}")
            return False

# ì „ì—­ ìºì‹œ ë§¤ë‹ˆì € ì¸ìŠ¤í„´ìŠ¤
_cache_manager = None

def get_cache_manager(aws_profile: str = None) -> S3CacheManager:
    """ìºì‹œ ë§¤ë‹ˆì € ì‹±ê¸€í†¤ ì¸ìŠ¤í„´ìŠ¤ ë°˜í™˜"""
    global _cache_manager
    if _cache_manager is None:
        _cache_manager = S3CacheManager(aws_profile)
    return _cache_manager

# í¸ì˜ í•¨ìˆ˜ë“¤
def is_s3_path(path: str) -> bool:
    """ê²½ë¡œê°€ S3 ê²½ë¡œì¸ì§€ í™•ì¸"""
    return get_cache_manager().is_s3_path(path)

def cache_join(*parts: str) -> str:
    """ìºì‹œ ê²½ë¡œ ì¡°í•©"""
    if not parts:
        return ""
    return get_cache_manager().join_path(parts[0], *parts[1:])

def cache_exists(path: str) -> bool:
    """ìºì‹œ íŒŒì¼ ì¡´ì¬ ì—¬ë¶€ í™•ì¸"""
    return get_cache_manager().exists(path)

def cache_makedirs(path: str, exist_ok: bool = True):
    """ìºì‹œ ë””ë ‰í† ë¦¬ ìƒì„±"""
    get_cache_manager().makedirs(path, exist_ok)

def cache_save_pickle(path: str, data: Any) -> bool:
    """ìºì‹œ í”¼í´ ì €ì¥"""
    return get_cache_manager().save_pickle(path, data)

def cache_load_pickle(path: str) -> Optional[Any]:
    """ìºì‹œ í”¼í´ ë¡œë“œ"""
    return get_cache_manager().load_pickle(path)

def cache_remove(path: str) -> bool:
    """ìºì‹œ íŒŒì¼ ì‚­ì œ"""
    return get_cache_manager().remove(path) 