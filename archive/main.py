import os
import cv2
import numpy as np
import mediapipe as mp
from tqdm import tqdm
from sklearn.model_selection import train_test_split
import tensorflow as tf
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import LSTM, Dense, Dropout
from tensorflow.keras.preprocessing.sequence import pad_sequences
from tensorflow.keras.utils import to_categorical

# MediaPipe ì´ˆê¸°í™”
mp_holistic = mp.solutions.holistic
holistic = mp_holistic.Holistic()

# ê²½ë¡œ ë° ìƒìˆ˜ ì„¤ì •
VIDEO_ROOT = "/Volumes/Sub_Storage/ìˆ˜ì–´ ë°ì´í„°ì…‹/0001~3000(á„‹á…§á†¼á„‰á…¡á†¼)"
MAX_SEQ_LENGTH = 100  # ìµœëŒ€ í”„ë ˆì„ ê¸¸ì´ (íŒ¨ë”©ì— ì‚¬ìš©)
AUGMENTATIONS_PER_VIDEO = 9 # ì›ë³¸ 1ê°œë‹¹ ìƒì„±í•  ì¦ê°• ë°ì´í„° ìˆ˜
DATA_CACHE_PATH = 'preprocessed_data_multiclass.npz'
MODEL_SAVE_PATH = 'lstm_model_multiclass.keras'
ACTIONS = ["Fire", "Toilet", "None"]

label_dict = {
    # Fire
    "KETI_SL_0000000419.MOV": "Fire",
    "KETI_SL_0000000838.MTS": "Fire",
    "KETI_SL_0000001255.MTS": "Fire",
    "KETI_SL_0000001674.MTS": "Fire",
    "KETI_SL_0000002032.MOV": "Fire",
    "KETI_SL_0000002451.MP4": "Fire",
    "KETI_SL_0000002932.MOV": "Fire",
    # Toilet
    "KETI_SL_0000000418.MOV": "Toilet",
    "KETI_SL_0000000837.MTS": "Toilet",
    "KETI_SL_0000001254.MTS": "Toilet",
    "KETI_SL_0000001673.MTS": "Toilet",
    "KETI_SL_0000002031.MOV": "Toilet",
    "KETI_SL_0000002450.MP4": "Toilet",
    "KETI_SL_0000002931.MOV": "Toilet"
}

def augment_sequence(sequence, noise_level=0.005, scale_range=0.05):
    """ëœë“œë§ˆí¬ ì‹œí€€ìŠ¤ì— ë…¸ì´ì¦ˆ ì¶”ê°€ ë° í¬ê¸° ì¡°ì ˆì„ ì ìš©í•˜ì—¬ ì¦ê°•í•©ë‹ˆë‹¤."""
    augmented_sequence = sequence.copy()

    # 1. ë…¸ì´ì¦ˆ ì¶”ê°€
    noise = np.random.normal(0, noise_level, augmented_sequence.shape)
    augmented_sequence += noise

    # 2. í¬ê¸° ì¡°ì ˆ
    scale_factor = 1.0 + np.random.uniform(-scale_range, scale_range)
    augmented_sequence *= scale_factor

    return augmented_sequence

def extract_landmarks(video_path):
    cap = cv2.VideoCapture(video_path)
    landmarks_list = []
    
    while cap.isOpened():
        ret, frame = cap.read()
        if not ret:
            break
            
        rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
        results = holistic.process(rgb_frame)
        
        frame_data = {
            "pose": results.pose_landmarks,
            "left_hand": results.left_hand_landmarks,
            "right_hand": results.right_hand_landmarks,
        }
        landmarks_list.append(frame_data)
    
    cap.release()
    return landmarks_list

def preprocess_landmarks(landmarks_list):
    processed_frames = []
    for frame in landmarks_list:
        combined = []
        # ì–¼êµ´ ëœë“œë§ˆí¬ ì œì™¸
        for key in ["pose", "left_hand", "right_hand"]:
            lm = frame[key]
            if lm:
                combined.extend([[l.x, l.y, l.z] for l in lm.landmark])
            else:
                num_points = {"pose": 33, "left_hand": 21, "right_hand": 21}[key]
                combined.extend([[0,0,0]] * num_points)
                
        arr = np.array(combined)
        # ëœë“œë§ˆí¬ê°€ í•˜ë‚˜ë„ ì—†ëŠ” ê²½ìš°ì— ëŒ€í•œ ì˜ˆì™¸ ì²˜ë¦¬
        if arr.shape[0] == 0:
            # í¬ì¦ˆ(33) + ì™¼ì†(21) + ì˜¤ë¥¸ì†(21) = 75ê°œì˜ ëœë“œë§ˆí¬
            return np.zeros((len(landmarks_list), 75 * 3))
            
        root = arr[0].copy()
        arr -= root
        
        max_val = np.max(np.abs(arr))
        if max_val > 0:
            arr /= max_val
            
        processed_frames.append(arr.flatten())
        
    return np.array(processed_frames)

# --- 1. ë°ì´í„° ë¡œë”© ë˜ëŠ” ì¶”ì¶œ ---
if os.path.exists(DATA_CACHE_PATH):
    print(f"ğŸ’¾ ìºì‹œì—ì„œ ì „ì²˜ë¦¬ëœ ë°ì´í„° ë¡œë”©: {DATA_CACHE_PATH}")
    cached_data = np.load(DATA_CACHE_PATH)
    X_padded = cached_data['X']
    y_one_hot = cached_data['y']
else:
    print("âœ¨ ë°ì´í„° ìºì‹œ ì—†ìŒ. ë¹„ë””ì˜¤ì—ì„œ ëœë“œë§ˆí¬ ì¶”ì¶œ ë° ì¦ê°•ì„ ì‹œì‘í•©ë‹ˆë‹¤.")
    X = []
    y = []

    for filename, label in tqdm(label_dict.items()):
        file_id = filename.split(".")[0]
        actual_path = os.path.join(VIDEO_ROOT, f"{file_id}.avi")
        
        if not os.path.exists(actual_path):
            print(f"âš ï¸ íŒŒì¼ ì—†ìŒ: {actual_path}")
            continue
        
        landmarks = extract_landmarks(actual_path)
        if not landmarks:
            continue
            
        processed_sequence = preprocess_landmarks(landmarks)
        
        # ì›ë³¸ ë°ì´í„° ì¶”ê°€
        X.append(processed_sequence)
        y.append(ACTIONS.index(label))

        # ì¦ê°• ë°ì´í„° ì¶”ê°€
        for _ in range(AUGMENTATIONS_PER_VIDEO):
            augmented = augment_sequence(processed_sequence)
            X.append(augmented)
            y.append(ACTIONS.index(label))

    # 2. 'None' ë°ì´í„° ì¸ê³µì ìœ¼ë¡œ ìƒì„±
    print("\nâœ¨ 'None' í´ë˜ìŠ¤ ë°ì´í„° ìƒì„± ì¤‘...")
    # 'í™”ì¬' ì²«ë²ˆì§¸ ì˜ìƒì„ ê¸°ë°˜ìœ¼ë¡œ 'ê°€ë§Œíˆ ìˆëŠ”' ë°ì´í„° ìƒì„±
    base_video_path = os.path.join(VIDEO_ROOT, f"{list(label_dict.keys())[0].split('.')[0]}.avi")
    if os.path.exists(base_video_path):
        landmarks = extract_landmarks(base_video_path)
        if landmarks:
            # ì²« í”„ë ˆì„ë§Œ ì‚¬ìš©
            first_frame_landmarks = preprocess_landmarks([landmarks[0]])
            # 100í”„ë ˆì„ ë™ì•ˆ ê°€ë§Œíˆ ìˆëŠ” ì‹œí€€ìŠ¤ ìƒì„±
            still_sequence = np.tile(first_frame_landmarks, (MAX_SEQ_LENGTH, 1))
            
            # ì›ë³¸ ë° ì¦ê°• ë°ì´í„° ì¶”ê°€ (ì´ 10 * 7 = 70ê°œ)
            none_label_index = ACTIONS.index("None")
            for _ in range(10 * len(ACTIONS)): # ë‹¤ë¥¸ í´ë˜ìŠ¤ ìˆ˜ì™€ ë¹„ìŠ·í•˜ê²Œ ìƒì„±
                augmented = augment_sequence(still_sequence)
                X.append(augmented)
                y.append(none_label_index)

    X_padded = pad_sequences(X, maxlen=MAX_SEQ_LENGTH, padding='post', truncating='post', dtype='float32')
    y_one_hot = to_categorical(y, num_classes=len(ACTIONS))
    
    print(f"ğŸ’¾ ë‹¤ì¤‘ í´ë˜ìŠ¤ ë°ì´í„° ìºì‹œ ì €ì¥: {DATA_CACHE_PATH}")
    np.savez(DATA_CACHE_PATH, X=X_padded, y=y_one_hot)

print(f"âœ… ë°ì´í„° ì¤€ë¹„ ì™„ë£Œ: {X_padded.shape[0]}ê°œ ìƒ˜í”Œ")

# --- 2. ëª¨ë¸ í•™ìŠµ ë˜ëŠ” ë¡œë”© ---
if X_padded.shape[0] < 2:
    print("âš ï¸ ë°ì´í„°ê°€ ë¶€ì¡±í•˜ì—¬ ëª¨ë¸ì„ í•™ìŠµí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
else:
    X_train, X_test, y_train, y_test = train_test_split(
        X_padded, y_one_hot, test_size=0.2, random_state=42, stratify=y_one_hot
    )

    if os.path.exists(MODEL_SAVE_PATH):
        print(f"ğŸ§  ì €ì¥ëœ ëª¨ë¸ ë¡œë”©: {MODEL_SAVE_PATH}")
        model = tf.keras.models.load_model(MODEL_SAVE_PATH)
    else:
        print("ğŸ‹ï¸â€â™€ï¸ ì €ì¥ëœ ëª¨ë¸ ì—†ìŒ. ë‹¤ì¤‘ í´ë˜ìŠ¤ ë¶„ë¥˜ ëª¨ë¸ í•™ìŠµì„ ì‹œì‘í•©ë‹ˆë‹¤.")
        model = Sequential([
            LSTM(64, return_sequences=True, input_shape=(MAX_SEQ_LENGTH, X_padded.shape[2])),
            Dropout(0.5),
            LSTM(32),
            Dropout(0.5),
            Dense(16, activation='relu'),
            Dense(len(ACTIONS), activation='softmax') # 3ê°œì˜ í´ë˜ìŠ¤, softmax í™œì„±í™”
        ])

        model.compile(optimizer='adam',
                      loss='categorical_crossentropy', # ë‹¤ì¤‘ í´ë˜ìŠ¤ ì†ì‹¤ í•¨ìˆ˜
                      metrics=['accuracy'])

        print("\n--- ëª¨ë¸ í•™ìŠµ ì‹œì‘ ---")
        model.summary()

        history = model.fit(X_train, y_train, epochs=50, batch_size=16, validation_data=(X_test, y_test))
        
        print(f"ğŸ§  í•™ìŠµëœ ëª¨ë¸ ì €ì¥: {MODEL_SAVE_PATH}")
        model.save(MODEL_SAVE_PATH)

    # --- 3. ëª¨ë¸ í‰ê°€ ---
    print("\n--- ëª¨ë¸ í‰ê°€ ---")
    loss, accuracy = model.evaluate(X_test, y_test)
    print(f"ğŸš€ í…ŒìŠ¤íŠ¸ ì •í™•ë„: {accuracy * 100:.2f}%")

    # ì˜ˆì¸¡ ê²°ê³¼ í™•ì¸
    print("\n--- Test Sample Predictions ---")
    y_pred_prob = model.predict(X_test)
    y_pred_classes = np.argmax(y_pred_prob, axis=1)
    y_true_classes = np.argmax(y_test, axis=1)

    for i, (pred_class, true_class) in enumerate(zip(y_pred_classes, y_true_classes)):
        pred_label = ACTIONS[pred_class]
        actual_label = ACTIONS[true_class]
        result = "âœ…" if pred_class == true_class else "âŒ"
        confidence = y_pred_prob[i][pred_class]
        print(f"Sample {i+1}: Prediction={pred_label} (Confidence: {confidence:.2f}), Actual={actual_label} {result}")